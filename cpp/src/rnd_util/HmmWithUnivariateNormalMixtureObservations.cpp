#include "swl/Config.h"
#include "swl/rnd_util/HmmWithUnivariateNormalMixtureObservations.h"
#include "RndUtilLocalApi.h"
#include <boost/numeric/ublas/matrix_proxy.hpp>
#include <boost/math/distributions/normal.hpp>  // for normal distribution
#include <boost/random/normal_distribution.hpp>
#include <boost/random/variate_generator.hpp>
#include <iostream>
#include <stdexcept>


#if defined(_DEBUG) && defined(__SWL_CONFIG__USE_DEBUG_NEW)
#include "swl/ResourceLeakageCheck.h"
#define new DEBUG_NEW
#endif


namespace swl {

HmmWithUnivariateNormalMixtureObservations::HmmWithUnivariateNormalMixtureObservations(const size_t K, const size_t C)
: base_type(K, 1), HmmWithMixtureObservations(C, K), mus_(K, C, 0.0), sigmas_(K, C, 0.0),  // 0-based index
  mus_conj_(), betas_conj_(), sigmas_conj_(), nus_conj_(),
  baseGenerator_()
{
}

HmmWithUnivariateNormalMixtureObservations::HmmWithUnivariateNormalMixtureObservations(const size_t K, const size_t C, const dvector_type &pi, const dmatrix_type &A, const dmatrix_type &alphas, const dmatrix_type &mus, const dmatrix_type &sigmas)
: base_type(K, 1, pi, A), HmmWithMixtureObservations(C, K, alphas), mus_(mus), sigmas_(sigmas),
  mus_conj_(), betas_conj_(), sigmas_conj_(), nus_conj_(),
  baseGenerator_()
{
}

HmmWithUnivariateNormalMixtureObservations::HmmWithUnivariateNormalMixtureObservations(const size_t K, const size_t C, const dvector_type *pi_conj, const dmatrix_type *A_conj, const dmatrix_type *alphas_conj, const dmatrix_type *mus_conj, const dmatrix_type *betas_conj, const dmatrix_type *sigmas_conj, const dmatrix_type *nus_conj)
: base_type(K, 1, pi_conj, A_conj), HmmWithMixtureObservations(C, K, alphas_conj), mus_(K, C, 0.0), sigmas_(K, C, 0.0),
  mus_conj_(mus_conj), betas_conj_(betas_conj), sigmas_conj_(sigmas_conj), nus_conj_(nus_conj),
  baseGenerator_()
{
}

HmmWithUnivariateNormalMixtureObservations::~HmmWithUnivariateNormalMixtureObservations()
{
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByML(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double denominatorA)
{
	// reestimate observation(emission) distribution in each state.

	size_t c, n;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
		std::vector<boost::math::normal> pdfs;
		pdfs.reserve(C_);
		for (c = 0; c < C_; ++c)
			pdfs.push_back(boost::math::normal(mus_(state, c), sigmas_(state, c)));

		const double eps = 1e-50;
		double val;
		for (n = 0; n < N; ++n)
		{
			const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
#if 0
				val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
				val = alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]);
#endif

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	denominator = denominatorA + gamma(N-1, state);
	const double factorAlpha = 0.999 / denominator;

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (n = 0; n < N; ++n)
			sumZeta += zeta(n, c);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * sumZeta;

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = 0.0;
		for (n = 0; n < N; ++n)
			mu += zeta(n, c) * observations(n, 0);
		mu = 0.001 + 0.999 * mu / sumZeta;

		//
		double &sigma = sigmas_(state, c);
		sigma = 0.0;
		for (n = 0; n < N; ++n)
			sigma += zeta(n, c) * (observations(n, 0) - mu) * (observations(n, 0) - mu);
		sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByML(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const size_t R, const double denominatorA)
{
	// reestimate observation(emission) distribution in each state.

	size_t c, n, r;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
		std::vector<boost::math::normal> pdfs;
		pdfs.reserve(C_);
		for (c = 0; c < C_; ++c)
			pdfs.push_back(boost::math::normal(mus_(state, c), sigmas_(state, c)));

		const double eps = 1e-50;
		double val;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationSequences[r], n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
#if 0
					val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
					val = alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]);
#endif

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	denominator = denominatorA;
	for (r = 0; r < R; ++r)
		denominator += gammas[r](Ns[r]-1, state);
	const double factorAlpha = 0.999 / denominator;

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sumZeta += zetar(n, c);
		}

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * sumZeta;

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				mu += zetar(n, c) * observationr(n, 0);
		}
		mu = 0.001 + 0.999 * mu / sumZeta;

		//
		double &sigma = sigmas_(state, c);
		sigma = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sigma += zetar(n, c) * (observationr(n, 0) - mu) * (observationr(n, 0) - mu);
		}
		sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingConjugatePrior(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double denominatorA)
{
	// reestimate observation(emission) distribution in each state.

	size_t c, n;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
		std::vector<boost::math::normal> pdfs;
		pdfs.reserve(C_);
		for (c = 0; c < C_; ++c)
			pdfs.push_back(boost::math::normal(mus_(state, c), sigmas_(state, c)));

		const double eps = 1e-50;
		double val;
		for (n = 0; n < N; ++n)
		{
			const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
#if 0
				val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
				val = alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]);
#endif

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	denominator = denominatorA + gamma(N-1, state);
	double denominatorAlpha0 = -double(C_);
	for (c = 0; c < C_; ++c)
		denominatorAlpha0 += (*alphas_conj_)(state, c);
	const double factorAlpha = 0.999 / (denominator + denominatorAlpha0);

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (n = 0; n < N; ++n)
			sumZeta += zeta(n, c);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * (sumZeta + (*alphas_conj_)(state, c) - 1.0);

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = (*betas_conj_)(state, c) * (*mus_conj_)(state, c);
		for (n = 0; n < N; ++n)
			mu += zeta(n, c) * observations(n, 0);
		mu = 0.001 + 0.999 * mu / (sumZeta + (*betas_conj_)(state, c));

		//
		double &sigma = sigmas_(state, c);
		sigma = (*sigmas_conj_)(state, c) + (*betas_conj_)(state, c) * (mu - (*mus_conj_)(state, c)) * (mu - (*mus_conj_)(state, c));
		for (n = 0; n < N; ++n)
			sigma += zeta(n, c) * (observations(n, 0) - mu) * (observations(n, 0) - mu);
		sigma = 0.001 + 0.999 * std::sqrt(sigma / (sumZeta + (*nus_conj_)(state, c) - D_));
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingConjugatePrior(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const size_t R, const double denominatorA)
{
	// reestimate observation(emission) distribution in each state.

	size_t c, n, r;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
		std::vector<boost::math::normal> pdfs;
		pdfs.reserve(C_);
		for (c = 0; c < C_; ++c)
			pdfs.push_back(boost::math::normal(mus_(state, c), sigmas_(state, c)));

		const double eps = 1e-50;
		double val;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationSequences[r], n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
#if 0
					val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
					val = alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]);
#endif

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	denominator = denominatorA;
	for (r = 0; r < R; ++r)
		denominator += gammas[r](Ns[r]-1, state);
	double denominatorAlpha0 = -double(C_);
	for (c = 0; c < C_; ++c)
		denominatorAlpha0 += (*alphas_conj_)(state, c);
	const double factorAlpha = 0.999 / (denominator + denominatorAlpha0);

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sumZeta += zetar(n, c);
		}

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * (sumZeta + (*alphas_conj_)(state, c) - 1.0);

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = (*betas_conj_)(state, c) * (*mus_conj_)(state, c);
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				mu += zetar(n, c) * observationr(n, 0);
		}
		mu = 0.001 + 0.999 * mu / (sumZeta + (*betas_conj_)(state, c));

		//
		double &sigma = sigmas_(state, c);
		sigma = (*sigmas_conj_)(state, c) + (*betas_conj_)(state, c) * (mu - (*mus_conj_)(state, c)) * (mu - (*mus_conj_)(state, c));
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sigma += zetar(n, c) * (observationr(n, 0) - mu) * (observationr(n, 0) - mu);
		}
		sigma = 0.001 + 0.999 * std::sqrt(sigma / (sumZeta + (*nus_conj_)(state, c) - D_));
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingEntropicPrior(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double z, const double terminationTolerance, const size_t maxIteration, const double /*denominatorA*/)
{
	// reestimate observation(emission) distribution in each state.

	size_t c, n;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
		std::vector<boost::math::normal> pdfs;
		pdfs.reserve(C_);
		for (c = 0; c < C_; ++c)
			pdfs.push_back(boost::math::normal(mus_(state, c), sigmas_(state, c)));

		const double eps = 1e-50;
		double val;
		for (n = 0; n < N; ++n)
		{
			const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
#if 0
				val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
				val = alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]);
#endif

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	// reestimate mixture coefficients(weights).
	{
		std::vector<double> omega(C_, 0.0), theta(C_, 0.0);
		for (c = 0; c < C_; ++c)
		{
			omega[c] = 0.0;
			for (n = 0; n < N; ++n)
				omega[c] += zeta(n, c);
		}

		double entropicMAPLogLikelihood = 0.0;
		const bool retval = computeMAPEstimateOfMultinomialUsingEntropicPrior(omega, z, theta, entropicMAPLogLikelihood, terminationTolerance, maxIteration, false);
		assert(retval);
		for (c = 0; c < C_; ++c)
			alphas_(state, c) = theta[c];
	}

	//
	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (n = 0; n < N; ++n)
			sumZeta += zeta(n, c);

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = 0.0;
		for (n = 0; n < N; ++n)
			mu += zeta(n, c) * observations(n, 0);
		mu = 0.001 + 0.999 * mu / sumZeta;

		//
		double &sigma = sigmas_(state, c);
		sigma = 0.0;
		for (n = 0; n < N; ++n)
			sigma += zeta(n, c) * (observations(n, 0) - mu) * (observations(n, 0) - mu);
		sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingEntropicPrior(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const double z, const size_t R, const double terminationTolerance, const size_t maxIteration, const double /*denominatorA*/)
{
	// reestimate observation(emission) distribution in each state.

	size_t c, n, r;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
		std::vector<boost::math::normal> pdfs;
		pdfs.reserve(C_);
		for (c = 0; c < C_; ++c)
			pdfs.push_back(boost::math::normal(mus_(state, c), sigmas_(state, c)));

		const double eps = 1e-50;
		double val;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationSequences[r], n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
#if 0
					val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
					val = alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]);
#endif

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	// reestimate mixture coefficients(weights).
	{
		std::vector<double> omega(C_, 0.0), theta(C_, 0.0);
		for (c = 0; c < C_; ++c)
		{
			omega[c] = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &zetar = zetas[r];
				for (n = 0; n < Ns[r]; ++n)
					omega[c] += zetar(n, c);
			}
		}

		double entropicMAPLogLikelihood = 0.0;
		const bool retval = computeMAPEstimateOfMultinomialUsingEntropicPrior(omega, z, theta, entropicMAPLogLikelihood, terminationTolerance, maxIteration, false);
		assert(retval);
		for (c = 0; c < C_; ++c)
			alphas_(state, c) = theta[c];
	}

	//
	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sumZeta += zetar(n, c);
		}

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				mu += zetar(n, c) * observationr(n, 0);
		}
		mu = 0.001 + 0.999 * mu / sumZeta;

		//
		double &sigma = sigmas_(state, c);
		sigma = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sigma += zetar(n, c) * (observationr(n, 0) - mu) * (observationr(n, 0) - mu);
		}
		sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

double HmmWithUnivariateNormalMixtureObservations::doEvaluateEmissionProbability(const unsigned int state, const boost::numeric::ublas::matrix_row<const dmatrix_type> &observation) const
{
	double prob = 0.0;
	for (size_t c = 0; c < C_; ++c)
	{
		//boost::math::normal pdf;  // (default mean = zero, and standard deviation = unity)
		boost::math::normal pdf(mus_(state, c), sigmas_(state, c));

		prob += alphas_(state, c) * boost::math::pdf(pdf, observation[0]);
	}

	return prob;
}

void HmmWithUnivariateNormalMixtureObservations::doGenerateObservationsSymbol(const unsigned int state, boost::numeric::ublas::matrix_row<dmatrix_type> &observation, const unsigned int seed /*= (unsigned int)-1*/) const
{
	// PRECONDITIONS [] >>
	//	-. std::srand() had to be called before this function is called.

	const double prob = (double)std::rand() / RAND_MAX;

	double accum = 0.0;
	unsigned int component = (unsigned int)C_;
	for (size_t c = 0; c < C_; ++c)
	{
		accum += alphas_(state, c);
		if (prob < accum)
		{
			component = (unsigned int)c;
			break;
		}
	}

	// TODO [check] >>
	if ((unsigned int)C_ == component)
		component = (unsigned int)(C_ - 1);

	//
	typedef boost::normal_distribution<> distribution_type;
	typedef boost::variate_generator<base_generator_type &, distribution_type> generator_type;

	if ((unsigned int)-1 != seed)
		baseGenerator_.seed(seed);

	generator_type normal_gen(baseGenerator_, distribution_type(mus_(state, component), sigmas_(state, component)));
	observation[0] = normal_gen();
}

bool HmmWithUnivariateNormalMixtureObservations::doReadObservationDensity(std::istream &stream)
{
	if (1 != D_) return false;

	std::string dummy;
	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "univariate") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "univariate") != 0)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "normal") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "normal") != 0)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "mixture:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "mixture:") != 0)
#endif
		return false;

	// TODO [check] >>
	size_t C;
	stream >> dummy >> C;  // the number of mixture components
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "C=") != 0 || C_ != C)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "C=") != 0 || C_ != C)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "alpha:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "alpha:") != 0)
#endif
		return false;

	size_t k, c;

	// K x C
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> alphas_(k, c);

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "mu:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "mu:") != 0)
#endif
		return false;

	// K x C
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> mus_(k, c);

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "sigma:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "sigma:") != 0)
#endif
		return false;

	// K x C
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> sigmas_(k, c);

	return true;
}

bool HmmWithUnivariateNormalMixtureObservations::doWriteObservationDensity(std::ostream &stream) const
{
	stream << "univariate normal mixture:" << std::endl;

	stream << "C= " << C_ << std::endl;  // the number of mixture components

	size_t k, c;

	// K x C
	stream << "alpha:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << alphas_(k, c) << ' ';
		stream << std::endl;
	}

	// K x C
	stream << "mu:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << mus_(k, c) << ' ';
		stream << std::endl;
	}

	// K x C
	stream << "sigma:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << sigmas_(k, c) << ' ';
		stream << std::endl;
	}

	return true;
}

void HmmWithUnivariateNormalMixtureObservations::doInitializeObservationDensity(const std::vector<double> &lowerBoundsOfObservationDensity, const std::vector<double> &upperBoundsOfObservationDensity)
{
	// PRECONDITIONS [] >>
	//	-. std::srand() had to be called before this function is called.

	// initialize mixture coefficients(weights)
	{
		double sum = 0.0;
		size_t c;
		for (size_t k = 0; k < K_; ++k)
		{
			for (c = 0; c < C_; ++c)
			{
				alphas_(k, c) = (double)std::rand() / RAND_MAX;
				sum += alphas_(k, c);
			}
			for (c = 0; c < C_; ++c)
				alphas_(k, c) /= sum;
		}
	}

	// initialize the parameters of observation density
	const std::size_t numLowerBound = lowerBoundsOfObservationDensity.size();
	const std::size_t numUpperBound = upperBoundsOfObservationDensity.size();

	const std::size_t numParameters = K_ * C_ * D_ * 2;  // the total number of parameters of observation density

	assert(numLowerBound == numUpperBound);
	assert(1 == numLowerBound || numParameters == numLowerBound);

	if (1 == numLowerBound)
	{
		const double lb = lowerBoundsOfObservationDensity[0], ub = upperBoundsOfObservationDensity[0];
		size_t c;
		for (size_t k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c)
			{
				mus_(k, c) = ((double)std::rand() / RAND_MAX) * (ub - lb) + lb;
				// TODO [check] >> all standard deviations have to be positive.
				sigmas_(k, c) = ((double)std::rand() / RAND_MAX) * (ub - lb) + lb;
			}
 	}
	else if (numParameters == numLowerBound)
	{
		size_t k, c, idx = 0;
		for (k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c, ++idx)
				mus_(k, c) = ((double)std::rand() / RAND_MAX) * (upperBoundsOfObservationDensity[idx] - lowerBoundsOfObservationDensity[idx]) + lowerBoundsOfObservationDensity[idx];
		for (k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c, ++idx)
				// TODO [check] >> all standard deviations have to be positive.
				sigmas_(k, c) = ((double)std::rand() / RAND_MAX) * (upperBoundsOfObservationDensity[idx] - lowerBoundsOfObservationDensity[idx]) + lowerBoundsOfObservationDensity[idx];
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

}  // namespace swl
