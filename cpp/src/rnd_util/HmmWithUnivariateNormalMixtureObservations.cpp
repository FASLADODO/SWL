#include "swl/Config.h"
#include "swl/rnd_util/HmmWithUnivariateNormalMixtureObservations.h"
#include "RndUtilLocalApi.h"
#include <boost/numeric/ublas/matrix_proxy.hpp>
#include <boost/math/distributions/normal.hpp>  // for normal distribution
#include <boost/random/normal_distribution.hpp>
#include <boost/random/variate_generator.hpp>
#include <numeric>
#include <iostream>
#include <stdexcept>
#include <cassert>


#if defined(_DEBUG) && defined(__SWL_CONFIG__USE_DEBUG_NEW)
#include "swl/ResourceLeakageCheck.h"
#define new DEBUG_NEW
#endif


namespace swl {

HmmWithUnivariateNormalMixtureObservations::HmmWithUnivariateNormalMixtureObservations(const size_t K, const size_t C)
: base_type(K, 1, C), mus_(K, C, 0.0), sigmas_(K, C, 0.0),  // 0-based index.
  mus_conj_(), betas_conj_(), sigmas_conj_(), nus_conj_(),
  baseGenerator_()
{
}

HmmWithUnivariateNormalMixtureObservations::HmmWithUnivariateNormalMixtureObservations(const size_t K, const size_t C, const dvector_type &pi, const dmatrix_type &A, const dmatrix_type &alphas, const dmatrix_type &mus, const dmatrix_type &sigmas)
: base_type(K, 1, C, pi, A, alphas), mus_(mus), sigmas_(sigmas),
  mus_conj_(), betas_conj_(), sigmas_conj_(), nus_conj_(),
  baseGenerator_()
{
}

HmmWithUnivariateNormalMixtureObservations::HmmWithUnivariateNormalMixtureObservations(const size_t K, const size_t C, const dvector_type *pi_conj, const dmatrix_type *A_conj, const dmatrix_type *alphas_conj, const dmatrix_type *mus_conj, const dmatrix_type *betas_conj, const dmatrix_type *sigmas_conj, const dmatrix_type *nus_conj)
: base_type(K, 1, C, pi_conj, A_conj, alphas_conj), mus_(K, C, 0.0), sigmas_(K, C, 0.0),
  mus_conj_(mus_conj), betas_conj_(betas_conj), sigmas_conj_(sigmas_conj), nus_conj_(nus_conj),
  baseGenerator_()
{
}

HmmWithUnivariateNormalMixtureObservations::~HmmWithUnivariateNormalMixtureObservations()
{
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByML(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double denominatorA)
{
	const double eps = 1e-50;
	size_t c, n;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
#if 1
		std::vector<boost::math::normal> pdfs;
		pdfs.reserve(C_);
		for (c = 0; c < C_; ++c)
			pdfs.push_back(std::fabs(alphas_(state, c)) < eps ? boost::math::normal() : boost::math::normal(mus_(state, c), sigmas_(state, c)));
#endif

		double denominator;
		double val;
		for (n = 0; n < N; ++n)
		{
			const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
#if 0
				val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
#else
				val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]));
#endif

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	const double sumGamma = denominatorA + gamma(N-1, state);
	assert(std::fabs(sumGamma) >= eps);
	const double factorAlpha = 0.999 / sumGamma;

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (n = 0; n < N; ++n)
			sumZeta += zeta(n, c);
		assert(std::fabs(sumZeta) >= eps);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * sumZeta;

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = 0.0;
		for (n = 0; n < N; ++n)
			mu += zeta(n, c) * observations(n, 0);
		mu = 0.001 + 0.999 * mu / sumZeta;

		//
		double &sigma = sigmas_(state, c);
		sigma = 0.0;
		for (n = 0; n < N; ++n)
			sigma += zeta(n, c) * (observations(n, 0) - mu) * (observations(n, 0) - mu);
		sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByML(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const size_t R, const double denominatorA)
{
	const double eps = 1e-50;
	size_t c, n, r;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
#if 1
		std::vector<boost::math::normal> pdfs;
		pdfs.reserve(C_);
		for (c = 0; c < C_; ++c)
			pdfs.push_back(std::fabs(alphas_(state, c)) < eps ? boost::math::normal() : boost::math::normal(mus_(state, c), sigmas_(state, c)));
#endif

		double denominator;
		double val;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationr, n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
#if 0
					val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
#else
					val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]));
#endif

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	double sumGamma = denominatorA;
	for (r = 0; r < R; ++r)
		sumGamma += gammas[r](Ns[r]-1, state);
	assert(std::fabs(sumGamma) >= eps);
	const double factorAlpha = 0.999 / sumGamma;

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sumZeta += zetar(n, c);
		}
		assert(std::fabs(sumZeta) >= eps);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * sumZeta;

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				mu += zetar(n, c) * observationr(n, 0);
		}
		mu = 0.001 + 0.999 * mu / sumZeta;

		//
		double &sigma = sigmas_(state, c);
		sigma = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sigma += zetar(n, c) * (observationr(n, 0) - mu) * (observationr(n, 0) - mu);
		}
		sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingConjugatePrior(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double denominatorA)
{
	const double eps = 1e-50;
	size_t c, n;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
#if 1
		std::vector<boost::math::normal> pdfs;
		pdfs.reserve(C_);
		for (c = 0; c < C_; ++c)
			pdfs.push_back(std::fabs(alphas_(state, c)) < eps ? boost::math::normal() : boost::math::normal(mus_(state, c), sigmas_(state, c)));
#endif

		double denominator;
		double val;
		for (n = 0; n < N; ++n)
		{
			const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
#if 0
				val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
#else
				val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]));
#endif

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	const double sumGamma = denominatorA + gamma(N-1, state);
	//assert(std::fabs(sumGamma) >= eps);
	double denominatorAlpha0 = -double(C_);
	for (c = 0; c < C_; ++c)
		denominatorAlpha0 += (*alphas_conj_)(state, c);
	const double factorAlpha = 0.999 / (sumGamma + denominatorAlpha0);

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (n = 0; n < N; ++n)
			sumZeta += zeta(n, c);
		//assert(std::fabs(sumZeta) >= eps);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * (sumZeta + (*alphas_conj_)(state, c) - 1.0);

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = (*betas_conj_)(state, c) * (*mus_conj_)(state, c);
		for (n = 0; n < N; ++n)
			mu += zeta(n, c) * observations(n, 0);
		mu = 0.001 + 0.999 * mu / (sumZeta + (*betas_conj_)(state, c));

		//
		double &sigma = sigmas_(state, c);
		sigma = (*sigmas_conj_)(state, c) + (*betas_conj_)(state, c) * (mu - (*mus_conj_)(state, c)) * (mu - (*mus_conj_)(state, c));
		for (n = 0; n < N; ++n)
			sigma += zeta(n, c) * (observations(n, 0) - mu) * (observations(n, 0) - mu);
		sigma = 0.001 + 0.999 * std::sqrt(sigma / (sumZeta + (*nus_conj_)(state, c) - D_));
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingConjugatePrior(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const size_t R, const double denominatorA)
{
	const double eps = 1e-50;
	size_t c, n, r;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
#if 1
		std::vector<boost::math::normal> pdfs;
		pdfs.reserve(C_);
		for (c = 0; c < C_; ++c)
			pdfs.push_back(std::fabs(alphas_(state, c)) < eps ? boost::math::normal() : boost::math::normal(mus_(state, c), sigmas_(state, c)));
#endif

		double denominator;
		double val;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationr, n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
#if 0
					val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
#else
					val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]));
#endif

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	double sumGamma = denominatorA;
	for (r = 0; r < R; ++r)
		sumGamma += gammas[r](Ns[r]-1, state);
	//assert(std::fabs(sumGamma) >= eps);
	double denominatorAlpha0 = -double(C_);
	for (c = 0; c < C_; ++c)
		denominatorAlpha0 += (*alphas_conj_)(state, c);
	const double factorAlpha = 0.999 / (sumGamma + denominatorAlpha0);

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sumZeta += zetar(n, c);
		}
		//assert(std::fabs(sumZeta) >= eps);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * (sumZeta + (*alphas_conj_)(state, c) - 1.0);

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = (*betas_conj_)(state, c) * (*mus_conj_)(state, c);
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				mu += zetar(n, c) * observationr(n, 0);
		}
		mu = 0.001 + 0.999 * mu / (sumZeta + (*betas_conj_)(state, c));

		//
		double &sigma = sigmas_(state, c);
		sigma = (*sigmas_conj_)(state, c) + (*betas_conj_)(state, c) * (mu - (*mus_conj_)(state, c)) * (mu - (*mus_conj_)(state, c));
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sigma += zetar(n, c) * (observationr(n, 0) - mu) * (observationr(n, 0) - mu);
		}
		sigma = 0.001 + 0.999 * std::sqrt(sigma / (sumZeta + (*nus_conj_)(state, c) - D_));
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingEntropicPrior(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double z, const bool doesTrimParameter, const double terminationTolerance, const size_t maxIteration, const double /*denominatorA*/)
{
	const double eps = 1e-50;
	size_t c, n;

#if 1
	std::vector<boost::math::normal> pdfs;
	pdfs.reserve(C_);
	for (c = 0; c < C_; ++c)
		pdfs.push_back(std::fabs(alphas_(state, c)) < eps ? boost::math::normal() : boost::math::normal(mus_(state, c), sigmas_(state, c)));
#endif

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
		double denominator;
		double val;
		for (n = 0; n < N; ++n)
		{
			const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
				// TODO [check] >> we need to check if a component is trimmed or not.
				//	Here, we use the value of alpha in order to check if a component is trimmed or not.
#if 0
				val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
#else
				val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]));
#endif

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	{
		// compute expected sufficient statistics (ESS).
		std::vector<double> omega(C_, 0.0), theta(C_, 0.0);
		for (c = 0; c < C_; ++c)
		{
			omega[c] = 0.0;
			for (n = 0; n < N; ++n)
				omega[c] += zeta(n, c);
		}

		// reestimate mixture coefficients(weights).
		double entropicMAPLogLikelihood = 0.0;
		const bool retval = computeMAPEstimateOfMultinomialUsingEntropicPrior(omega, z, theta, entropicMAPLogLikelihood, terminationTolerance, maxIteration, false);
		assert(retval);

		// trim mixture coefficients(weights).
		if (doesTrimParameter && std::fabs(z - 1.0) <= eps)
		{
			dmatrix_type prob(N, C_, 0.0);
			for (n = 0; n < N; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);
				for (c = 0; c < C_; ++c)
				{
					// TODO [check] >> we need to check if a component is trimmed or not.
					//	Here, we use the value of alpha in order to check if a component is trimmed or not.
#if 0
					prob(n, c) = std::fabs(alphas_(state, c)) < eps ? 0.0 : doEvaluateEmissionMixtureComponentProbability(state, c, obs);
#else
					prob(n, c) = std::fabs(alphas_(state, c)) < eps ? 0.0 : boost::math::pdf(pdfs[c], obs[0]);
#endif
				}
			}

			size_t i;
			double grad;
			bool isNormalized = false;
			double numerator, denominator;
			for (c = 0; c < C_; ++c)
			{
				if (alphas_(state, c) >= eps)  // not yet trimmed.
				{
					grad = 0.0;
					for (n = 0; n < N; ++n)
					{
						numerator = prob(n, c);
						if (std::fabs(numerator) >= eps)
						{
							denominator = 0.0;
							for (i = 0; i < C_; ++i)
								denominator += prob(n, i) * theta[i];

							assert(std::fabs(denominator) >= eps);
							grad += numerator / denominator;
						}
						//else grad += 0.0;
					}

					if (theta[c] <= std::exp(-grad / z))
					{
						theta[c] = 0.0;
						isNormalized = true;
					}
				}
			}

			if (isNormalized)
			{
				double sumTheta = std::accumulate(theta.begin(), theta.end(), 0.0);
				assert(std::fabs(sumTheta) >= eps);
				for (c = 0; c < C_; ++c)
					alphas_(state, c) = theta[c] / sumTheta;
			}
			else
			{
				for (c = 0; c < C_; ++c)
					alphas_(state, c) = theta[c];
			}
		}
		else
		{
			for (c = 0; c < C_; ++c)
				alphas_(state, c) = theta[c];
		}
	}

	//
	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		if (alphas_(state, c) < eps)  // already trimmed.
		{
			mus_(state, c) = 0.0;
			sigmas_(state, c) = 0.0;
		}
		else
		{
			sumZeta = 0.0;
			for (n = 0; n < N; ++n)
				sumZeta += zeta(n, c);
			assert(std::fabs(sumZeta) >= eps);

			// reestimate observation(emission) distribution in each state.

			double &mu = mus_(state, c);
			mu = 0.0;
			for (n = 0; n < N; ++n)
				mu += zeta(n, c) * observations(n, 0);
			mu = 0.001 + 0.999 * mu / sumZeta;

			//
			double &sigma = sigmas_(state, c);
			sigma = 0.0;
			for (n = 0; n < N; ++n)
				sigma += zeta(n, c) * (observations(n, 0) - mu) * (observations(n, 0) - mu);
			sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
			assert(sigma > 0.0);
		}
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void HmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingEntropicPrior(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const double z, const bool doesTrimParameter, const double terminationTolerance, const size_t maxIteration, const size_t R, const double /*denominatorA*/)
{
	const double eps = 1e-50;
	size_t c, n, r;

#if 1
	std::vector<boost::math::normal> pdfs;
	pdfs.reserve(C_);
	for (c = 0; c < C_; ++c)
		pdfs.push_back(std::fabs(alphas_(state, c)) < eps ? boost::math::normal() : boost::math::normal(mus_(state, c), sigmas_(state, c)));
#endif

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
		double denominator;
		double val;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationr, n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
					// TODO [check] >> we need to check if a component is trimmed or not.
					//	Here, we use the value of alpha in order to check if a component is trimmed or not.
#if 0
					val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
#else
					val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * boost::math::pdf(pdfs[c], obs[0]));
#endif

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	{
		// compute expected sufficient statistics (ESS).
		std::vector<double> omega(C_, 0.0), theta(C_, 0.0);
		for (c = 0; c < C_; ++c)
		{
			omega[c] = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &zetar = zetas[r];
				for (n = 0; n < Ns[r]; ++n)
					omega[c] += zetar(n, c);
			}
		}

		// reestimate mixture coefficients(weights).
		double entropicMAPLogLikelihood = 0.0;
		const bool retval = computeMAPEstimateOfMultinomialUsingEntropicPrior(omega, z, theta, entropicMAPLogLikelihood, terminationTolerance, maxIteration, false);
		assert(retval);

		// trim mixture coefficients(weights).
		if (doesTrimParameter && std::fabs(z - 1.0) <= eps)
		{
			std::vector<dmatrix_type> probs(R);
			for (r = 0; r < R; ++r)
			{
				const size_t &Nr = Ns[r];
				const dmatrix_type &observationr = observationSequences[r];

				dmatrix_type &probr = probs[r];
				probr.resize(Nr, C_);
				for (n = 0; n < Nr; ++n)
				{
					const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationr, n);
					for (c = 0; c < C_; ++c)
					{
						// TODO [check] >> we need to check if a component is trimmed or not.
						//	Here, we use the value of alpha in order to check if a component is trimmed or not.
#if 0
						probr(n, c) = std::fabs(alphas_(state, c)) < eps ? 0.0 : doEvaluateEmissionMixtureComponentProbability(state, c, obs);
#else
						probr(n, c) = std::fabs(alphas_(state, c)) < eps ? 0.0 : boost::math::pdf(pdfs[c], obs[0]);
#endif
					}
				}
			}

			size_t i;
			double grad;
			bool isNormalized = false;
			double numerator, denominator;
			for (c = 0; c < C_; ++c)
			{
				if (alphas_(state, c) >= eps)  // not yet trimmed.
				{
					grad = 0.0;
					for (r = 0; r < R; ++r)
					{
						const size_t &Nr = Ns[r];
						const dmatrix_type &probr = probs[r];
						for (n = 0; n < Nr; ++n)
						{
							numerator = probr(n, c);
							if (std::fabs(numerator) >= eps)
							{
								denominator = 0.0;
								for (i = 0; i < C_; ++i)
									denominator += probr(n, i) * theta[i];

								assert(std::fabs(denominator) >= eps);
								grad += numerator / denominator;
							}
							//else grad += 0.0;
						}
					}

					if (theta[c] <= std::exp(-grad / z))
					{
						theta[c] = 0.0;
						isNormalized = true;
					}
				}
			}

			if (isNormalized)
			{
				double sumTheta = std::accumulate(theta.begin(), theta.end(), 0.0);
				assert(std::fabs(sumTheta) >= eps);
				for (c = 0; c < C_; ++c)
					alphas_(state, c) = theta[c] / sumTheta;
			}
			else
			{
				for (c = 0; c < C_; ++c)
					alphas_(state, c) = theta[c];
			}
		}
		else
		{
			for (c = 0; c < C_; ++c)
				alphas_(state, c) = theta[c];
		}
	}

	//
	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		if (alphas_(state, c) < eps)  // already trimmed.
		{
			mus_(state, c) = 0.0;
			sigmas_(state, c) = 0.0;
		}
		else
		{
			sumZeta = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &zetar = zetas[r];

				for (n = 0; n < Ns[r]; ++n)
					sumZeta += zetar(n, c);
			}
			assert(std::fabs(sumZeta) >= eps);

			// reestimate observation(emission) distribution in each state.

			double &mu = mus_(state, c);
			mu = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &observationr = observationSequences[r];
				const dmatrix_type &zetar = zetas[r];

				for (n = 0; n < Ns[r]; ++n)
					mu += zetar(n, c) * observationr(n, 0);
			}
			mu = 0.001 + 0.999 * mu / sumZeta;

			//
			double &sigma = sigmas_(state, c);
			sigma = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &observationr = observationSequences[r];
				const dmatrix_type &zetar = zetas[r];

				for (n = 0; n < Ns[r]; ++n)
					sigma += zetar(n, c) * (observationr(n, 0) - mu) * (observationr(n, 0) - mu);
			}
			sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
			assert(sigma > 0.0);
		}
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

double HmmWithUnivariateNormalMixtureObservations::doEvaluateEmissionMixtureComponentProbability(const unsigned int state, const unsigned int component, const dvector_type &observation) const
{
	assert(sigmas_(state, component) > 0.0);

	//boost::math::normal pdf;  // (default mean = zero, and standard deviation = unity)
	boost::math::normal pdf(mus_(state, component), sigmas_(state, component));
	//boost::math::normal pdf(std::fabs(alphas_(state, component)) < eps ? boost::math::normal() : mus_(state, component), sigmas_(state, component));

	return boost::math::pdf(pdf, observation[0]);
}

void HmmWithUnivariateNormalMixtureObservations::doGenerateObservationsSymbol(const unsigned int state, const size_t n, dmatrix_type &observations) const
{
	const double prob = (double)std::rand() / RAND_MAX;

	double accum = 0.0;
	unsigned int component = (unsigned int)C_;
	for (size_t c = 0; c < C_; ++c)
	{
		accum += alphas_(state, c);
		if (prob < accum)
		{
			component = (unsigned int)c;
			break;
		}
	}

	// TODO [check] >>
	if ((unsigned int)C_ == component)
		component = (unsigned int)(C_ - 1);

	//
	typedef boost::normal_distribution<> distribution_type;
	typedef boost::variate_generator<base_generator_type &, distribution_type> generator_type;

	generator_type normal_gen(baseGenerator_, distribution_type(mus_(state, component), sigmas_(state, component)));
	observations(n, 0) = normal_gen();
}

void HmmWithUnivariateNormalMixtureObservations::doInitializeRandomSampleGeneration(const unsigned int seed /*= (unsigned int)-1*/) const
{
	if ((unsigned int)-1 != seed)
	{
		std::srand(seed);
		baseGenerator_.seed(seed);
	}
}

bool HmmWithUnivariateNormalMixtureObservations::doReadObservationDensity(std::istream &stream)
{
	if (1 != D_) return false;

	std::string dummy;
	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "univariate") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "univariate") != 0)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "normal") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "normal") != 0)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "mixture:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "mixture:") != 0)
#endif
		return false;

	// TODO [check] >>
	size_t C;
	stream >> dummy >> C;  // the number of mixture components.
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "C=") != 0 || C_ != C)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "C=") != 0 || C_ != C)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "alpha:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "alpha:") != 0)
#endif
		return false;

	size_t k, c;

	// K x C.
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> alphas_(k, c);

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "mu:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "mu:") != 0)
#endif
		return false;

	// K x C.
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> mus_(k, c);

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "sigma:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "sigma:") != 0)
#endif
		return false;

	// K x C.
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> sigmas_(k, c);

	return true;
}

bool HmmWithUnivariateNormalMixtureObservations::doWriteObservationDensity(std::ostream &stream) const
{
	stream << "univariate normal mixture:" << std::endl;

	stream << "C= " << C_ << std::endl;  // the number of mixture components.

	size_t k, c;

	// K x C.
	stream << "alpha:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << alphas_(k, c) << ' ';
		stream << std::endl;
	}

	// K x C.
	stream << "mu:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << mus_(k, c) << ' ';
		stream << std::endl;
	}

	// K x C.
	stream << "sigma:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << sigmas_(k, c) << ' ';
		stream << std::endl;
	}

	return true;
}

void HmmWithUnivariateNormalMixtureObservations::doInitializeObservationDensity(const std::vector<double> &lowerBoundsOfObservationDensity, const std::vector<double> &upperBoundsOfObservationDensity)
{
	// PRECONDITIONS [] >>
	//	-. std::srand() has to be called before this function is called.

	// initialize mixture coefficients(weights).
	{
		double sum = 0.0;
		size_t c;
		for (size_t k = 0; k < K_; ++k)
		{
			for (c = 0; c < C_; ++c)
			{
				alphas_(k, c) = (double)std::rand() / RAND_MAX;
				sum += alphas_(k, c);
			}
			for (c = 0; c < C_; ++c)
				alphas_(k, c) /= sum;
		}
	}

	// initialize the parameters of observation density.
	const std::size_t numLowerBound = lowerBoundsOfObservationDensity.size();
	const std::size_t numUpperBound = upperBoundsOfObservationDensity.size();

	const std::size_t numParameters = K_ * C_ * D_ * 2;  // the total number of parameters of observation density.

	assert(numLowerBound == numUpperBound);
	assert(1 == numLowerBound || numParameters == numLowerBound);

	if (1 == numLowerBound)
	{
		const double lb = lowerBoundsOfObservationDensity[0], ub = upperBoundsOfObservationDensity[0];
		size_t c;
		for (size_t k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c)
			{
				mus_(k, c) = ((double)std::rand() / RAND_MAX) * (ub - lb) + lb;
				// TODO [check] >> all standard deviations have to be positive.
				sigmas_(k, c) = ((double)std::rand() / RAND_MAX) * (ub - lb) + lb;
			}
 	}
	else if (numParameters == numLowerBound)
	{
		size_t k, c, idx = 0;
		for (k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c, ++idx)
				mus_(k, c) = ((double)std::rand() / RAND_MAX) * (upperBoundsOfObservationDensity[idx] - lowerBoundsOfObservationDensity[idx]) + lowerBoundsOfObservationDensity[idx];
		for (k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c, ++idx)
				// TODO [check] >> all standard deviations have to be positive.
				sigmas_(k, c) = ((double)std::rand() / RAND_MAX) * (upperBoundsOfObservationDensity[idx] - lowerBoundsOfObservationDensity[idx]) + lowerBoundsOfObservationDensity[idx];
	}

	for (size_t k = 0; k < K_; ++k)
		for (size_t c = 0; c < C_; ++c)
		{
			// all standard deviations have to be positive.
			if (sigmas_(k, c) < 0.0)
				sigmas_(k, c) = -sigmas_(k, c);
		}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

}  // namespace swl
