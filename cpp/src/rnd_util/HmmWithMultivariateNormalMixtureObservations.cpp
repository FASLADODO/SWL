#include "swl/Config.h"
#include "swl/rnd_util/HmmWithMultivariateNormalMixtureObservations.h"
#include "RndUtilLocalApi.h"
#include "swl/math/MathConstant.h"
#include <gsl/gsl_rng.h>
#include <gsl/gsl_randist.h>
#include <boost/numeric/ublas/matrix_proxy.hpp>
#include <boost/numeric/ublas/blas.hpp>
#include <boost/numeric/ublas/lu.hpp>
#include <boost/math/constants/constants.hpp>
#include <numeric>
#include <ctime>
#include <stdexcept>
#include <cassert>


#if defined(_DEBUG) && defined(__SWL_CONFIG__USE_DEBUG_NEW)
#include "swl/ResourceLeakageCheck.h"
#define new DEBUG_NEW
#endif


namespace swl {

// [ref] swl/src/rnd_util/RndUtilLocalApi.cpp
double det_and_inv_by_lu(const boost::numeric::ublas::matrix<double> &m, boost::numeric::ublas::matrix<double> &inv);

HmmWithMultivariateNormalMixtureObservations::HmmWithMultivariateNormalMixtureObservations(const size_t K, const size_t D, const size_t C)
: base_type(K, D), HmmWithMixtureObservations(C, K), mus_(boost::extents[K][C]), sigmas_(boost::extents[K][C]),  // 0-based index
  mus_conj_(), betas_conj_(), sigmas_conj_(), nus_conj_(),
  r_(NULL)
{
	for (size_t k = 0; k < K; ++k)
		for (size_t c = 0; c < C; ++c)
		{
			mus_[k][c].resize(D);
			sigmas_[k][c].resize(D, D);
		}
}

HmmWithMultivariateNormalMixtureObservations::HmmWithMultivariateNormalMixtureObservations(const size_t K, const size_t D, const size_t C, const dvector_type &pi, const dmatrix_type &A, const dmatrix_type &alphas, const boost::multi_array<dvector_type, 2> &mus, const boost::multi_array<dmatrix_type, 2> &sigmas)
: base_type(K, D, pi, A), HmmWithMixtureObservations(C, K, alphas), mus_(mus), sigmas_(sigmas),
  mus_conj_(), betas_conj_(), sigmas_conj_(), nus_conj_(),
  r_(NULL)
{
}

HmmWithMultivariateNormalMixtureObservations::HmmWithMultivariateNormalMixtureObservations(const size_t K, const size_t D, const size_t C, const dvector_type *pi_conj, const dmatrix_type *A_conj, const dmatrix_type *alphas_conj, const boost::multi_array<dvector_type, 2> *mus_conj, const dmatrix_type *betas_conj, const boost::multi_array<dmatrix_type, 2> *sigmas_conj, const dmatrix_type *nus_conj)
: base_type(K, D, pi_conj, A_conj), HmmWithMixtureObservations(C, K, alphas_conj), mus_(boost::extents[K][C]), sigmas_(boost::extents[K][C]),
  mus_conj_(mus_conj), betas_conj_(betas_conj), sigmas_conj_(sigmas_conj), nus_conj_(nus_conj),
  r_(NULL)
{
}

HmmWithMultivariateNormalMixtureObservations::~HmmWithMultivariateNormalMixtureObservations()
{
}

void HmmWithMultivariateNormalMixtureObservations::doEstimateObservationDensityParametersByML(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double denominatorA)
{
	size_t c, n;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
		const double eps = 1e-50;
		double val;
		dmatrix_type inv(D_, D_);
		for (n = 0; n < N; ++n)
		{
			const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
#if 0
				val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
				{
					const dmatrix_type &sigma = sigmas_[state][c];
					//if (0 == c)
					//	inv.resize(sigma.size1(), sigma.size2());
					const double det = det_and_inv_by_lu(sigma, inv);

					const dvector_type x_mu(obs - mus_[state][c]);
					val = alphas_(state, c) * std::exp(-0.5 * boost::numeric::ublas::inner_prod(x_mu, boost::numeric::ublas::prod(inv, x_mu))) / std::sqrt(std::pow(MathConstant::_2_PI, (double)D_) * det);
				}
#endif

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	denominator = denominatorA + gamma(N-1, state);
	const double factorAlpha = 0.999 / denominator;

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (n = 0; n < N; ++n)
			sumZeta += zeta(n, c);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * sumZeta;

		// reestimate symbol prob in each state.
		dvector_type &mu = mus_[state][c];
		mu.clear();
		for (n = 0; n < N; ++n)
			mu += zeta(n, c) * boost::numeric::ublas::matrix_row<const dmatrix_type>(observations, n);
		//mu = mu * (0.999 / sumZeta) + boost::numeric::ublas::scalar_vector<double>(mu.size(), 0.001);
		mu = mu * (0.999 / sumZeta) + boost::numeric::ublas::scalar_vector<double>(D_, 0.001);

		//
		dmatrix_type &sigma = sigmas_[state][c];
		sigma.clear();
		for (n = 0; n < N; ++n)
			boost::numeric::ublas::blas_2::sr(sigma, gamma(n, state), boost::numeric::ublas::matrix_row<const dmatrix_type>(observations, n) - mu);
		sigma = 0.5 * (sigma + boost::numeric::ublas::trans(sigma));

		//sigma = sigma * (0.999 / sumZeta) + boost::numeric::ublas::scalar_matrix<double>(sigma.size1(), sigma.size2(), 0.001);
		sigma = sigma * (0.999 / sumZeta) + boost::numeric::ublas::scalar_matrix<double>(D_, D_, 0.001);
	}

	// POSTCONDITIONS [] >>
	//	-. all covariance matrices have to be symmetric positive definite.
}

void HmmWithMultivariateNormalMixtureObservations::doEstimateObservationDensityParametersByML(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const size_t R, const double denominatorA)
{
	size_t c, n, r;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
		const double eps = 1e-50;
		double val;
		dmatrix_type inv(D_, D_);
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationSequences[r], n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
#if 0
					val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
					{
						const dmatrix_type &sigma = sigmas_[state][c];
						//if (0 == c)
						//	inv.resize(sigma.size1(), sigma.size2());
						const double det = det_and_inv_by_lu(sigma, inv);

						const dvector_type x_mu(obs - mus_[state][c]);
						val = alphas_(state, c) * std::exp(-0.5 * boost::numeric::ublas::inner_prod(x_mu, boost::numeric::ublas::prod(inv, x_mu))) / std::sqrt(std::pow(MathConstant::_2_PI, (double)D_) * det);
					}
#endif

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	denominator = denominatorA;
	for (r = 0; r < R; ++r)
		denominator += gammas[r](Ns[r]-1, state);
	const double factorAlpha = 0.999 / denominator;

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sumZeta += zetar(n, c);
		}

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * sumZeta;

		// reestimate observation(emission) distribution in each state.
		dvector_type &mu = mus_[state][c];
		mu.clear();
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				mu += zetar(n, c) * boost::numeric::ublas::matrix_row<const dmatrix_type>(observationr, n);
		}
		//mu = mu * (0.999 / sumZeta) + boost::numeric::ublas::scalar_vector<double>(mu.size(), 0.001);
		mu = mu * (0.999 / sumZeta) + boost::numeric::ublas::scalar_vector<double>(D_, 0.001);

		//
		dmatrix_type &sigma = sigmas_[state][c];
		sigma.clear();
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				boost::numeric::ublas::blas_2::sr(sigma, zetar(n, c), boost::numeric::ublas::matrix_row<const dmatrix_type>(observationr, n) - mu);
		}
		sigma = 0.5 * (sigma + boost::numeric::ublas::trans(sigma));

		//sigma = sigma * (0.999 / sumZeta) + boost::numeric::ublas::scalar_matrix<double>(sigma.size1(), sigma.size2(), 0.001);
		sigma = sigma * (0.999 / sumZeta) + boost::numeric::ublas::scalar_matrix<double>(D_, D_, 0.001);
	}

	// POSTCONDITIONS [] >>
	//	-. all covariance matrices have to be symmetric positive definite.
}

void HmmWithMultivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingConjugatePrior(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double denominatorA)
{
	size_t c, n;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
		const double eps = 1e-50;
		double val;
		dmatrix_type inv(D_, D_);
		for (n = 0; n < N; ++n)
		{
			const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
#if 0
				val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
				{
					const dmatrix_type &sigma = sigmas_[state][c];
					//if (0 == c)
					//	inv.resize(sigma.size1(), sigma.size2());
					const double det = det_and_inv_by_lu(sigma, inv);

					const dvector_type x_mu(obs - mus_[state][c]);
					val = alphas_(state, c) * std::exp(-0.5 * boost::numeric::ublas::inner_prod(x_mu, boost::numeric::ublas::prod(inv, x_mu))) / std::sqrt(std::pow(MathConstant::_2_PI, (double)D_) * det);
				}
#endif

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state

	denominator = denominatorA + gamma(N-1, state);
	double denominatorAlpha0 = -double(C_);
	for (c = 0; c < C_; ++c)
		denominatorAlpha0 += (*alphas_conj_)(state, c);
	const double factorAlpha = 0.999 / (denominator + denominatorAlpha0);

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (n = 0; n < N; ++n)
			sumZeta += zeta(n, c);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * (sumZeta + (*alphas_conj_)(state, c) - 1.0);

		// reestimate symbol prob in each state.
		dvector_type &mu = mus_[state][c];
		mu = (*betas_conj_)(state, c) * (*mus_conj_)[state][c];
		for (n = 0; n < N; ++n)
			mu += zeta(n, c) * boost::numeric::ublas::matrix_row<const dmatrix_type>(observations, n);
		//mu = mu * (0.999 / (sumZeta + (*betas_conj_)(state, c))) + boost::numeric::ublas::scalar_vector<double>(mu.size(), 0.001);
		mu = mu * (0.999 / (sumZeta + (*betas_conj_)(state, c))) + boost::numeric::ublas::scalar_vector<double>(D_, 0.001);

		//
		dmatrix_type &sigma = sigmas_[state][c];
		sigma = (*sigmas_conj_)[state][c];
		boost::numeric::ublas::blas_2::sr(sigma, (*betas_conj_)(state, c), mu - (*mus_conj_)[state][c]);
		for (n = 0; n < N; ++n)
			boost::numeric::ublas::blas_2::sr(sigma, gamma(n, state), boost::numeric::ublas::matrix_row<const dmatrix_type>(observations, n) - mu);
		sigma = 0.5 * (sigma + boost::numeric::ublas::trans(sigma));

		//sigma = sigma * (0.999 / (sumZeta + (*nus_conj_)(state, c) - D_)) + boost::numeric::ublas::scalar_matrix<double>(sigma.size1(), sigma.size2(), 0.001);
		sigma = sigma * (0.999 / (sumZeta + (*nus_conj_)(state, c) - D_)) + boost::numeric::ublas::scalar_matrix<double>(D_, D_, 0.001);
	}

	// POSTCONDITIONS [] >>
	//	-. all covariance matrices have to be symmetric positive definite.
}

void HmmWithMultivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingConjugatePrior(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const size_t R, const double denominatorA)
{
	size_t c, n, r;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
		const double eps = 1e-50;
		double val;
		dmatrix_type inv(D_, D_);
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationSequences[r], n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
#if 0
					val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
					{
						const dmatrix_type &sigma = sigmas_[state][c];
						//if (0 == c)
						//	inv.resize(sigma.size1(), sigma.size2());
						const double det = det_and_inv_by_lu(sigma, inv);

						const dvector_type x_mu(obs - mus_[state][c]);
						val = alphas_(state, c) * std::exp(-0.5 * boost::numeric::ublas::inner_prod(x_mu, boost::numeric::ublas::prod(inv, x_mu))) / std::sqrt(std::pow(MathConstant::_2_PI, (double)D_) * det);
					}
#endif

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	denominator = denominatorA;
	for (r = 0; r < R; ++r)
		denominator += gammas[r](Ns[r]-1, state);
	double denominatorAlpha0 = -double(C_);
	for (c = 0; c < C_; ++c)
		denominatorAlpha0 += (*alphas_conj_)(state, c);
	const double factorAlpha = 0.999 / (denominator + denominatorAlpha0);

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sumZeta += zetar(n, c);
		}

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * (sumZeta + (*alphas_conj_)(state, c) - 1.0);

		// reestimate observation(emission) distribution in each state.
		dvector_type &mu = mus_[state][c];
		mu = (*betas_conj_)(state, c) * (*mus_conj_)[state][c];
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				mu += zetar(n, c) * boost::numeric::ublas::matrix_row<const dmatrix_type>(observationr, n);
		}
		//mu = mu * (0.999 / (sumZeta + (*betas_conj_)(state, c))) + boost::numeric::ublas::scalar_vector<double>(mu.size(), 0.001);
		mu = mu * (0.999 / (sumZeta + (*betas_conj_)(state, c))) + boost::numeric::ublas::scalar_vector<double>(D_, 0.001);

		//
		dmatrix_type &sigma = sigmas_[state][c];
		sigma = (*sigmas_conj_)[state][c];
		boost::numeric::ublas::blas_2::sr(sigma, (*betas_conj_)(state, c), mu - (*mus_conj_)[state][c]);
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				boost::numeric::ublas::blas_2::sr(sigma, zetar(n, c), boost::numeric::ublas::matrix_row<const dmatrix_type>(observationr, n) - mu);
		}
		sigma = 0.5 * (sigma + boost::numeric::ublas::trans(sigma));

		//sigma = sigma * (0.999 / (sumZeta + (*nus_conj_)(state, c) - D_)) + boost::numeric::ublas::scalar_matrix<double>(sigma.size1(), sigma.size2(), 0.001);
		sigma = sigma * (0.999 / (sumZeta + (*nus_conj_)(state, c) - D_)) + boost::numeric::ublas::scalar_matrix<double>(D_, D_, 0.001);
	}

	// POSTCONDITIONS [] >>
	//	-. all covariance matrices have to be symmetric positive definite.
}

void HmmWithMultivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingEntropicPrior(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double z, const bool doesTrimParameter, const double terminationTolerance, const size_t maxIteration, const double /*denominatorA*/)
{
	size_t c, n;
	double denominator;
	const double eps = 1e-50;

	dmatrix_type inv(D_, D_);

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
		double val;
		for (n = 0; n < N; ++n)
		{
			const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
#if 0
				val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
				{
					const dmatrix_type &sigma = sigmas_[state][c];
					//if (0 == c)
					//	inv.resize(sigma.size1(), sigma.size2());
					const double det = det_and_inv_by_lu(sigma, inv);

					const dvector_type x_mu(obs - mus_[state][c]);
					val = alphas_(state, c) * std::exp(-0.5 * boost::numeric::ublas::inner_prod(x_mu, boost::numeric::ublas::prod(inv, x_mu))) / std::sqrt(std::pow(MathConstant::_2_PI, (double)D_) * det);
				}
#endif

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	// reestimate mixture coefficients(weights).
	{
		std::vector<double> omega(C_, 0.0), theta(C_, 0.0);
		for (c = 0; c < C_; ++c)
		{
			omega[c] = 0.0;
			for (n = 0; n < N; ++n)
				omega[c] += zeta(n, c);
		}

		double entropicMAPLogLikelihood = 0.0;
		const bool retval = computeMAPEstimateOfMultinomialUsingEntropicPrior(omega, z, theta, entropicMAPLogLikelihood, terminationTolerance, maxIteration, false);
		assert(retval);

		// trim mixture coefficients(weights).
		if (doesTrimParameter)
		{
			// FIXME [fix] >>
			throw std::runtime_error("not yet implemented");

			double numerator;
			dmatrix_type prob(N, C_, 0.0);
			for (n = 0; n < N; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);
				for (c = 0; c < C_; ++c)
#if 0
					prob(n, c) = doEvaluateEmissionProbability(state, obs);  // error !!!
#else
					{
						const dmatrix_type &sigma = sigmas_[state][c];
						//if (0 == c)
						//	inv.resize(sigma.size1(), sigma.size2());
						const double det = det_and_inv_by_lu(sigma, inv);

						const dvector_type x_mu(obs - mus_[state][c]);
						prob(n, c) = std::exp(-0.5 * boost::numeric::ublas::inner_prod(x_mu, boost::numeric::ublas::prod(inv, x_mu))) / std::sqrt(std::pow(MathConstant::_2_PI, (double)D_) * det);
					}
#endif
			}

			size_t i;
			bool isTrimmed = false;
			for (c = 0; c < C_; ++c)
			{
				numerator = 0.0;
				denominator = 0.0;
				for (n = 0; n < N; ++n)
				{
					numerator += prob(n, c);
					for (i = 0; i < C_; ++i)
						denominator += prob(n, i) * theta[i];
				}

				if (theta[c] <= std::exp(-numerator / denominator))
				{
					theta[c] = 0.0;
					isTrimmed = true;
				}
			}

			if (isTrimmed)
			{
				double sumTheta = std::accumulate(theta.begin(), theta.end(), 0.0);
				assert(std::fabs(sumTheta) >= eps);
				for (c = 0; c < C_; ++c)
					theta[c] /= sumTheta;
			}
		}

		for (c = 0; c < C_; ++c)
			alphas_(state, c) = theta[c];
	}

	//
	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (n = 0; n < N; ++n)
			sumZeta += zeta(n, c);

		// reestimate symbol prob in each state.
		dvector_type &mu = mus_[state][c];
		mu.clear();
		for (n = 0; n < N; ++n)
			mu += zeta(n, c) * boost::numeric::ublas::matrix_row<const dmatrix_type>(observations, n);
		//mu = mu * (0.999 / sumZeta) + boost::numeric::ublas::scalar_vector<double>(mu.size(), 0.001);
		mu = mu * (0.999 / sumZeta) + boost::numeric::ublas::scalar_vector<double>(D_, 0.001);

		//
		dmatrix_type &sigma = sigmas_[state][c];
		sigma.clear();
		for (n = 0; n < N; ++n)
			boost::numeric::ublas::blas_2::sr(sigma, gamma(n, state), boost::numeric::ublas::matrix_row<const dmatrix_type>(observations, n) - mu);
		sigma = 0.5 * (sigma + boost::numeric::ublas::trans(sigma));

		//sigma = sigma * (0.999 / sumZeta) + boost::numeric::ublas::scalar_matrix<double>(sigma.size1(), sigma.size2(), 0.001);
		sigma = sigma * (0.999 / sumZeta) + boost::numeric::ublas::scalar_matrix<double>(D_, D_, 0.001);
	}

	// POSTCONDITIONS [] >>
	//	-. all covariance matrices have to be symmetric positive definite.
}

void HmmWithMultivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingEntropicPrior(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const double z, const bool doesTrimParameter, const double terminationTolerance, const size_t maxIteration, const size_t R, const double /*denominatorA*/)
{
	size_t c, n, r;
	double denominator;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
		const double eps = 1e-50;
		double val;
		dmatrix_type inv(D_, D_);
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationSequences[r], n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
#if 0
					val = alphas_(state, c) * doEvaluateEmissionProbability(state, obs);  // error !!!
#else
					{
						const dmatrix_type &sigma = sigmas_[state][c];
						//if (0 == c)
						//	inv.resize(sigma.size1(), sigma.size2());
						const double det = det_and_inv_by_lu(sigma, inv);

						const dvector_type x_mu(obs - mus_[state][c]);
						val = alphas_(state, c) * std::exp(-0.5 * boost::numeric::ublas::inner_prod(x_mu, boost::numeric::ublas::prod(inv, x_mu))) / std::sqrt(std::pow(MathConstant::_2_PI, (double)D_) * det);
					}
#endif

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	// reestimate mixture coefficients(weights).
	{
		std::vector<double> omega(C_, 0.0), theta(C_, 0.0);
		for (c = 0; c < C_; ++c)
		{
			omega[c] = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &zetar = zetas[r];
				for (n = 0; n < Ns[r]; ++n)
					omega[c] += zetar(n, c);
			}
		}

		double entropicMAPLogLikelihood = 0.0;
		const bool retval = computeMAPEstimateOfMultinomialUsingEntropicPrior(omega, z, theta, entropicMAPLogLikelihood, terminationTolerance, maxIteration, false);
		assert(retval);

		// trim mixture coefficients(weights).
		if (doesTrimParameter)
		{
			throw std::runtime_error("not yet implemented");
		}

		for (c = 0; c < C_; ++c)
			alphas_(state, c) = theta[c];
	}

	//
	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sumZeta += zetar(n, c);
		}

		// reestimate observation(emission) distribution in each state.
		dvector_type &mu = mus_[state][c];
		mu.clear();
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				mu += zetar(n, c) * boost::numeric::ublas::matrix_row<const dmatrix_type>(observationr, n);
		}
		//mu = mu * (0.999 / sumZeta) + boost::numeric::ublas::scalar_vector<double>(mu.size(), 0.001);
		mu = mu * (0.999 / sumZeta) + boost::numeric::ublas::scalar_vector<double>(D_, 0.001);

		//
		dmatrix_type &sigma = sigmas_[state][c];
		sigma.clear();
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				boost::numeric::ublas::blas_2::sr(sigma, zetar(n, c), boost::numeric::ublas::matrix_row<const dmatrix_type>(observationr, n) - mu);
		}
		sigma = 0.5 * (sigma + boost::numeric::ublas::trans(sigma));

		//sigma = sigma * (0.999 / sumZeta) + boost::numeric::ublas::scalar_matrix<double>(sigma.size1(), sigma.size2(), 0.001);
		sigma = sigma * (0.999 / sumZeta) + boost::numeric::ublas::scalar_matrix<double>(D_, D_, 0.001);
	}

	// POSTCONDITIONS [] >>
	//	-. all covariance matrices have to be symmetric positive definite.
}

double HmmWithMultivariateNormalMixtureObservations::doEvaluateEmissionProbability(const unsigned int state, const boost::numeric::ublas::matrix_row<const dmatrix_type> &observation) const
{
	double prob = 0.0;
	dmatrix_type inv(D_, D_, 0.0);
	for (size_t c = 0; c < C_; ++c)
	{
		const dmatrix_type &sigma = sigmas_[state][c];
		//if (0 == c)
		//	inv.resize(sigma.size1(), sigma.size2());
		const double det = det_and_inv_by_lu(sigma, inv);

		const dvector_type x_mu(observation - mus_[state][c]);
		prob += alphas_(state, c) * std::exp(-0.5 * boost::numeric::ublas::inner_prod(x_mu, boost::numeric::ublas::prod(inv, x_mu))) / std::sqrt(std::pow(MathConstant::_2_PI, (double)D_) * det);
	}

	return prob;
}

void HmmWithMultivariateNormalMixtureObservations::doGenerateObservationsSymbol(const unsigned int state, boost::numeric::ublas::matrix_row<dmatrix_type> &observation) const
{
	assert(NULL != r_);

	// bivariate normal distribution.
	if (2 == D_)
	{
		const double prob = (double)std::rand() / RAND_MAX;

		double accum = 0.0;
		unsigned int component = (unsigned int)C_;
		for (size_t c = 0; c < C_; ++c)
		{
			accum += alphas_(state, c);
			if (prob < accum)
			{
				component = (unsigned int)c;
				break;
			}
		}

		// TODO [check] >>
		if ((unsigned int)C_ == component)
			component = (unsigned int)(C_ - 1);

		//
		const dvector_type &mu = mus_[state][component];
		const dmatrix_type &cov = sigmas_[state][component];

		const double sigma_x = std::sqrt(cov(0, 0));  // sigma_x = sqrt(cov_xx).
		const double sigma_y = std::sqrt(cov(1, 1));  // sigma_y = sqrt(cov_yy).
		const double rho = cov(0, 1) / (sigma_x * sigma_y);  // correlation coefficient: rho = cov_xy / (sigma_x * sigma_y).

		double x = 0.0, y = 0.0;
		gsl_ran_bivariate_gaussian(r_, sigma_x, sigma_y, rho, &x, &y);

		observation[0] = mu[0] + x;
		observation[1] = mu[1] + y;
	}
	else
	{
		throw std::runtime_error("not yet implemented");
	}
}

void HmmWithMultivariateNormalMixtureObservations::doInitializeRandomSampleGeneration(const unsigned int seed /*= (unsigned int)-1*/) const
{
	if ((unsigned int)-1 != seed)
	{
		// random number generator algorithms.
		gsl_rng_default = gsl_rng_mt19937;
		//gsl_rng_default = gsl_rng_taus;
		gsl_rng_default_seed = seed;
	}

	const gsl_rng_type *T = gsl_rng_default;
	r_ = gsl_rng_alloc(T);
}

void HmmWithMultivariateNormalMixtureObservations::doFinalizeRandomSampleGeneration() const
{
	gsl_rng_free(r_);
	r_ = NULL;
}

bool HmmWithMultivariateNormalMixtureObservations::doReadObservationDensity(std::istream &stream)
{
	std::string dummy;
	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "multivariate") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "multivariate") != 0)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "normal") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "normal") != 0)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "mixture:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "mixture:") != 0)
#endif
		return false;

	// TODO [check] >>
	size_t C;
	stream >> dummy >> C;  // the number of mixture components.
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "C=") != 0 || C_ != C)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "C=") != 0 || C_ != C)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "alpha:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "alpha:") != 0)
#endif
		return false;

	size_t i, k, c, d;

	// K x C
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> alphas_(k, c);

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "mu:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "mu:") != 0)
#endif
		return false;

	// K x C x D.
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
		{
			dvector_type &mu = mus_[k][c];

			for (d = 0; d < D_; ++d)
				stream >> mu[d];
		}

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "covariance:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "covariance:") != 0)
#endif
		return false;

	// K x C x (D * D).
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
		{
			dmatrix_type &sigma = sigmas_[k][c];

			for (d = 0; d < D_; ++d)
				for (i = 0; i < D_; ++i)
					stream >> sigma(d, i);
		}

	return true;
}

bool HmmWithMultivariateNormalMixtureObservations::doWriteObservationDensity(std::ostream &stream) const
{
	stream << "multivariate normal mixture:" << std::endl;

	stream << "C= " << C_ << std::endl;  // the number of mixture components

	size_t i, k, c, d;

	// K x C.
	stream << "alpha:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << alphas_(k, c) << ' ';
		stream << std::endl;
	}

	// K x C x D.
	stream << "mu:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
		{
			const dvector_type &mu = mus_[k][c];

			for (d = 0; d < D_; ++d)
				stream << mu[d] << ' ';
			stream << std::endl;
		}
		stream << std::endl;
	}

	// K x C x (D * D).
	stream << "covariance:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
		{
			const dmatrix_type &sigma = sigmas_[k][c];

			for (d = 0; d < D_; ++d)
			{
				for (i = 0; i < D_; ++i)
					stream << sigma(d, i) << ' ';
				stream << "  ";
			}
			stream << std::endl;
		}
		stream << std::endl;
	}

	return true;
}

void HmmWithMultivariateNormalMixtureObservations::doInitializeObservationDensity(const std::vector<double> &lowerBoundsOfObservationDensity, const std::vector<double> &upperBoundsOfObservationDensity)
{
	// PRECONDITIONS [] >>
	//	-. std::srand() has to be called before this function is called.

	// initialize mixture coefficients(weights).
	{
		double sum;
		size_t c;
		for (size_t k = 0; k < K_; ++k)
		{
			sum = 0.0;
			for (c = 0; c < C_; ++c)
			{
				alphas_(k, c) = (double)std::rand() / RAND_MAX;
				sum += alphas_(k, c);
			}
			for (c = 0; c < C_; ++c)
				alphas_(k, c) /= sum;
		}
	}

	// initialize the parameters of observation density.
	const std::size_t numLowerBound = lowerBoundsOfObservationDensity.size();
	const std::size_t numUpperBound = upperBoundsOfObservationDensity.size();

	const std::size_t numParameters = K_ * C_ * (D_ + D_ * D_);  // the total number of parameters of observation density.

	assert(numLowerBound == numUpperBound);
	assert(1 == numLowerBound || numParameters == numLowerBound);

	if (1 == numLowerBound)
	{
		const double lb = lowerBoundsOfObservationDensity[0], ub = upperBoundsOfObservationDensity[0];
		size_t c, d, i;
		for (size_t k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c)
			{
				dvector_type &mu = mus_[k][c];
				dmatrix_type &sigma = sigmas_[k][c];
				for (d = 0; d < D_; ++d)
				{
					mu[d] = ((double)std::rand() / RAND_MAX) * (ub - lb) + lb;
					for (i = 0; i < D_; ++i)
						sigma(d, i) = ((double)std::rand() / RAND_MAX) * (ub - lb) + lb;
				}
			}
 	}
	else if (numParameters == numLowerBound)
	{
		size_t k, c, d, i, idx = 0;
		for (k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c)
			{
				dvector_type &mu = mus_[k][c];
				for (d = 0; d < D_; ++d, ++idx)
					mu[d] = ((double)std::rand() / RAND_MAX) * (upperBoundsOfObservationDensity[idx] - lowerBoundsOfObservationDensity[idx]) + lowerBoundsOfObservationDensity[idx];
			}
		for (k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c)
			{
				dmatrix_type &sigma = sigmas_[k][c];
				for (d = 0; d < D_; ++d)
					for (i = 0; i < D_; ++i, ++idx)
						sigma(d, i) = ((double)std::rand() / RAND_MAX) * (upperBoundsOfObservationDensity[idx] - lowerBoundsOfObservationDensity[idx]) + lowerBoundsOfObservationDensity[idx];
			}
	}

	for (size_t k = 0; k < K_; ++k)
		for (size_t c = 0; c < C_; ++c)
		{
			dmatrix_type &sigma = sigmas_[k][c];
			// TODO [check] >> all covariance matrices have to be symmetric positive definite.
			sigma = 0.5 * (sigma + boost::numeric::ublas::trans(sigma));
		}

	// POSTCONDITIONS [] >>
	//	-. all covariance matrices have to be symmetric positive definite.
}

}  // namespace swl
