#include "swl/Config.h"
#include "swl/rnd_util/ArHmmWithUnivariateNormalMixtureObservations.h"
#include "RndUtilLocalApi.h"
#include <boost/numeric/ublas/matrix_proxy.hpp>
#include <boost/math/distributions/normal.hpp>  // for normal distribution.
#include <boost/random/normal_distribution.hpp>
#include <boost/random/variate_generator.hpp>
#include <numeric>
#include <iostream>
#include <stdexcept>
#include <cassert>


#if defined(_DEBUG) && defined(__SWL_CONFIG__USE_DEBUG_NEW)
#include "swl/ResourceLeakageCheck.h"
#define new DEBUG_NEW
#endif


namespace swl {

ArHmmWithUnivariateNormalMixtureObservations::ArHmmWithUnivariateNormalMixtureObservations(const size_t K, const size_t C, const size_t P)
: base_type(K, 1, C), mus_(K, C, 0.0), sigmas_(K, C, 0.0), Ws_(K, C, 0.0), P_(P),  // 0-based index.
  mus_conj_(), betas_conj_(), sigmas_conj_(), nus_conj_(),
  baseGenerator_()
{
}

ArHmmWithUnivariateNormalMixtureObservations::ArHmmWithUnivariateNormalMixtureObservations(const size_t K, const size_t C, const size_t P, const dvector_type &pi, const dmatrix_type &A, const dmatrix_type &alphas, const dmatrix_type &mus, const dmatrix_type &sigmas, const dmatrix_type &Ws)
: base_type(K, 1, C, pi, A, alphas), mus_(mus), sigmas_(sigmas), Ws_(Ws), P_(P),
  mus_conj_(), betas_conj_(), sigmas_conj_(), nus_conj_(),
  baseGenerator_()
{
}

ArHmmWithUnivariateNormalMixtureObservations::ArHmmWithUnivariateNormalMixtureObservations(const size_t K, const size_t C, const size_t P, const dvector_type *pi_conj, const dmatrix_type *A_conj, const dmatrix_type *alphas_conj, const dmatrix_type *mus_conj, const dmatrix_type *betas_conj, const dmatrix_type *sigmas_conj, const dmatrix_type *nus_conj)
: base_type(K, 1, C, pi_conj, A_conj, alphas_conj), mus_(K, C, 0.0), sigmas_(K, C, 0.0), Ws_(K, C, 0.0), P_(P),
  mus_conj_(mus_conj), betas_conj_(betas_conj), sigmas_conj_(sigmas_conj), nus_conj_(nus_conj),
  baseGenerator_()
{
	// FIXME [modify] >>
	throw std::runtime_error("not yet implemented");
}

ArHmmWithUnivariateNormalMixtureObservations::~ArHmmWithUnivariateNormalMixtureObservations()
{
}

void ArHmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByML(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double denominatorA)
{
	const double eps = 1e-50;
	size_t c, n;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
		double denominator;
		double val;
		for (n = 0; n < N; ++n)
		{
			//const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
				//val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
				val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, n, observations));

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	const double sumGamma = denominatorA + gamma(N-1, state);
	assert(std::fabs(sumGamma) >= eps);
	const double factorAlpha = 0.999 / sumGamma;

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (n = 0; n < N; ++n)
			sumZeta += zeta(n, c);
		assert(std::fabs(sumZeta) >= eps);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * sumZeta;

		// reestimate observation(emission) distribution in each state.

		// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
		double denominatorW = 0.0;  // zeta(0, c) * observations(-1, 0) * observations(-1, 0).
		for (n = 1; n < N; ++n)
			denominatorW += zeta(n, c) * observations(n-1, 0) * observations(n-1, 0);
		assert(std::fabs(denominatorW) >= eps);

		//
		double &W = Ws_(state, c);
		double &mu = mus_(state, c);

		const double tol = 1.0e-5;
		const size_t maxIteration = 1000;
		size_t iteration = 0;
		double oldMu = mu, oldW = W;
		while (iteration < maxIteration)
		{
			// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
			W = 0.0;  // zeta(0, c) * (observations(0, 0) - mu) * observations(-1, 0) = 0.
			for (n = 1; n < N; ++n)
				W += zeta(n, c) * (observations(n, 0) - mu) * observations(n-1, 0);
			W = 0.001 + 0.999 * W / denominatorW;
	
			// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
			mu = zeta(0, c) * observations(0, 0);  // zeta(0, c) * (observations(0, 0) - W * observations(-1, 0)).
			for (n = 1; n < N; ++n)
				mu += zeta(n, c) * (observations(n, 0) - W * observations(n-1, 0));
			mu = 0.001 + 0.999 * mu / sumZeta;

			if (std::fabs(W - oldW) <= tol && std::fabs(mu - oldMu) <= tol)
				break;

			oldW = W;
			oldMu = mu;

			++iteration;
		}

		//
		double &sigma = sigmas_(state, c);
		// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
		sigma = zeta(0, c) * std::pow(observations(0, 0) - mu, 2.0);  // zeta(0, c) * (observations(0, 0) - W * observations(-1, 0) - mu)^2.
		for (n = 1; n < N; ++n)
			sigma += zeta(n, c) * std::pow(observations(n, 0) - W * observations(n-1, 0) - mu, 2.0);
		sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void ArHmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByML(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const size_t R, const double denominatorA)
{
	const double eps = 1e-50;
	size_t c, n, r;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
		double denominator;
		double val;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				//const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationr, n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
					//val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
					val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, n, observationr));

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	double sumGamma = denominatorA;
	for (r = 0; r < R; ++r)
		sumGamma += gammas[r](Ns[r]-1, state);
	assert(std::fabs(sumGamma) >= eps);
	const double factorAlpha = 0.999 / sumGamma;

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sumZeta += zetar(n, c);
		}
		assert(std::fabs(sumZeta) >= eps);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * sumZeta;

		// reestimate observation(emission) distribution in each state.

		double denominatorW = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
			//denominatorW += 0.0;  // zetar(0, c) * observationr(-1, 0) * observationr(-1, 0) = 0.
			for (n = 1; n < Ns[r]; ++n)
				denominatorW += zetar(n, c) * observationr(n-1, 0) * observationr(n-1, 0);
		}
		assert(std::fabs(denominatorW) >= eps);

		//
		double &W = Ws_(state, c);
		double &mu = mus_(state, c);

		const double tol = 1.0e-5;
		const size_t maxIteration = 1000;
		size_t iteration = 0;
		double oldMu = mu, oldW = W;
		while (iteration < maxIteration)
		{
			W = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &observationr = observationSequences[r];
				const dmatrix_type &zetar = zetas[r];

				// TODO [check] >> assume x_-1 = observationr(-1, 0) = 0.
				//W += 0.0;  // zetar(0, c) * (observationr(0, 0) - mu) * observationr(-1, 0) = 0.
				for (n = 1; n < Ns[r]; ++n)
					W += zetar(n, c) * (observationr(n, 0) - mu) * observationr(n-1, 0);
			}
			W = 0.001 + 0.999 * W / denominatorW;

			mu = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &observationr = observationSequences[r];
				const dmatrix_type &zetar = zetas[r];
	
				// TODO [check] >> assume x_-1 = observationr(-1, 0) = 0.
				mu += zetar(0, c) * observationr(0, 0);  // zetar(0, c) * (observationr(0, 0) - W * observationr(-1, 0)).
				for (n = 1; n < Ns[r]; ++n)
					mu += zetar(n, c) * (observationr(n, 0) - W * observationr(n-1, 0));
			}
			mu = 0.001 + 0.999 * mu / sumZeta;

			if (std::fabs(W - oldW) <= tol && std::fabs(mu - oldMu) <= tol)
				break;

			oldW = W;
			oldMu = mu;

			++iteration;
		}

		//
		double &sigma = sigmas_(state, c);
		sigma = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			// TODO [check] >> assume x_-1 = observationr(-1, 0) = 0.
			sigma += zetar(0, c) * std::pow(observationr(0, 0) - mu, 2.0);  // zetar(0, c) * (observationr(0, 0) - W * observationr(-1, 0) - mu)^2.
			for (n = 1; n < Ns[r]; ++n)
				sigma += zetar(n, c) * std::pow(observationr(n, 0) - W * observationr(n-1, 0) - mu, 2.0);
		}
		sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void ArHmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingConjugatePrior(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double denominatorA)
{
	// FIXME [modify] >>
	throw std::runtime_error("not yet implemented");

	const double eps = 1e-50;
	size_t c, n;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
		double denominator;
		double val;
		for (n = 0; n < N; ++n)
		{
			//const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
				//val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
				val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, n, observations));

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	const double sumGamma = denominatorA + gamma(N-1, state);
	//assert(std::fabs(sumGamma) >= eps);
	double denominatorAlpha0 = -double(C_);
	for (c = 0; c < C_; ++c)
		denominatorAlpha0 += (*alphas_conj_)(state, c);
	const double factorAlpha = 0.999 / (sumGamma + denominatorAlpha0);

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (n = 0; n < N; ++n)
			sumZeta += zeta(n, c);
		//assert(std::fabs(sumZeta) >= eps);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * (sumZeta + (*alphas_conj_)(state, c) - 1.0);

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = (*betas_conj_)(state, c) * (*mus_conj_)(state, c);
		for (n = 0; n < N; ++n)
			mu += zeta(n, c) * observations(n, 0);
		mu = 0.001 + 0.999 * mu / (sumZeta + (*betas_conj_)(state, c));

		//
		double &sigma = sigmas_(state, c);
		sigma = (*sigmas_conj_)(state, c) + (*betas_conj_)(state, c) * (mu - (*mus_conj_)(state, c)) * (mu - (*mus_conj_)(state, c));
		for (n = 0; n < N; ++n)
			sigma += zeta(n, c) * (observations(n, 0) - mu) * (observations(n, 0) - mu);
		sigma = 0.001 + 0.999 * std::sqrt(sigma / (sumZeta + (*nus_conj_)(state, c) - D_));
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void ArHmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingConjugatePrior(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const size_t R, const double denominatorA)
{
	// FIXME [modify] >>
	throw std::runtime_error("not yet implemented");

	const double eps = 1e-50;
	size_t c, n, r;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
		double denominator;
		double val;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				//const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationr, n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
					//val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
					val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, n, observationr));

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	double sumGamma = denominatorA;
	for (r = 0; r < R; ++r)
		sumGamma += gammas[r](Ns[r]-1, state);
	//assert(std::fabs(sumGamma) >= eps);
	double denominatorAlpha0 = -double(C_);
	for (c = 0; c < C_; ++c)
		denominatorAlpha0 += (*alphas_conj_)(state, c);
	const double factorAlpha = 0.999 / (sumGamma + denominatorAlpha0);

	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		sumZeta = 0.0;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sumZeta += zetar(n, c);
		}
		//assert(std::fabs(sumZeta) >= eps);

		// reestimate mixture coefficients(weights).
		alphas_(state, c) = 0.001 + factorAlpha * (sumZeta + (*alphas_conj_)(state, c) - 1.0);

		// reestimate observation(emission) distribution in each state.
		double &mu = mus_(state, c);
		mu = (*betas_conj_)(state, c) * (*mus_conj_)(state, c);
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				mu += zetar(n, c) * observationr(n, 0);
		}
		mu = 0.001 + 0.999 * mu / (sumZeta + (*betas_conj_)(state, c));

		//
		double &sigma = sigmas_(state, c);
		sigma = (*sigmas_conj_)(state, c) + (*betas_conj_)(state, c) * (mu - (*mus_conj_)(state, c)) * (mu - (*mus_conj_)(state, c));
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
				sigma += zetar(n, c) * (observationr(n, 0) - mu) * (observationr(n, 0) - mu);
		}
		sigma = 0.001 + 0.999 * std::sqrt(sigma / (sumZeta + (*nus_conj_)(state, c) - D_));
		assert(sigma > 0.0);
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void ArHmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingEntropicPrior(const size_t N, const unsigned int state, const dmatrix_type &observations, const dmatrix_type &gamma, const double z, const bool doesTrimParameter, const double terminationTolerance, const size_t maxIteration, const double /*denominatorA*/)
{
	const double eps = 1e-40;
	size_t c, n;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	dmatrix_type zeta(N, C_, 0.0);
	{
		double denominator;
		double val;
		for (n = 0; n < N; ++n)
		{
			//const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);

			denominator = 0.0;
			for (c = 0; c < C_; ++c)
			{
				// TODO [check] >> we need to check if a component is trimmed or not.
				//	Here, we use the value of alpha in order to check if a component is trimmed or not.
				//val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
				val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, n, observations));

				zeta(n, c) = val;
				denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
			}

			if (denominator < eps)
			{
				// FIXME [check] >>
				//	because responsibilities, gamma(y_nc) means membership, the values may become zero if the corresponding mixture model doesn't generate a sample.
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.0;
			}
			else
			{
#if 0
				val = 0.999 * gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) = 0.001 + val * zeta(n, c);
#else
				val = gamma(n, state) / denominator;
				for (c = 0; c < C_; ++c)
					zeta(n, c) *= val;
#endif
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	{
		// compute expected sufficient statistics (ESS).
		std::vector<double> omega(C_, 0.0), theta(C_, 0.0);
		for (c = 0; c < C_; ++c)
		{
			omega[c] = 0.0;
			for (n = 0; n < N; ++n)
				omega[c] += zeta(n, c);
		}

		// reestimate mixture coefficients(weights).
		double entropicMAPLogLikelihood = 0.0;
		const bool retval = computeMAPEstimateOfMultinomialUsingEntropicPrior(omega, z, theta, entropicMAPLogLikelihood, terminationTolerance, maxIteration, false);
		assert(retval);

		// trim mixture coefficients(weights).
		if (doesTrimParameter && std::fabs(z - 1.0) <= eps)
		{
			dmatrix_type prob(N, C_, 0.0);
			for (n = 0; n < N; ++n)
			{
				//const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observations, n);
				for (c = 0; c < C_; ++c)
				{
					// TODO [check] >> we need to check if a component is trimmed or not.
					//	Here, we use the value of alpha in order to check if a component is trimmed or not.
					//prob(n, c) = std::fabs(alphas_(state, c)) < eps ? 0.0 : doEvaluateEmissionMixtureComponentProbability(state, c, obs);
					prob(n, c) = std::fabs(alphas_(state, c)) < eps ? 0.0 : doEvaluateEmissionMixtureComponentProbability(state, c, n, observations);
				}
			}

			size_t i;
			double grad;
			bool isNormalized = false;
			double numerator, denominator;
			for (c = 0; c < C_; ++c)
			{
				if (alphas_(state, c) >= eps)  // not yet trimmed.
				{
					grad = 0.0;
					for (n = 0; n < N; ++n)
					{
						numerator = prob(n, c);
						if (std::fabs(numerator) >= eps)
						{
							denominator = 0.0;
							for (i = 0; i < C_; ++i)
								denominator += prob(n, i) * theta[i];

							assert(std::fabs(denominator) >= eps);
							grad += numerator / denominator;
						}
						//else grad += 0.0;
					}

					if (theta[c] <= std::exp(-grad / z))
					{
						theta[c] = 0.0;
						isNormalized = true;
					}
				}
			}

			if (isNormalized)
			{
				double sumTheta = std::accumulate(theta.begin(), theta.end(), 0.0);
				assert(std::fabs(sumTheta) >= eps);
				for (c = 0; c < C_; ++c)
					alphas_(state, c) = theta[c] / sumTheta;
			}
			else
			{
				for (c = 0; c < C_; ++c)
					alphas_(state, c) = theta[c];
			}
		}
		else
		{
			for (c = 0; c < C_; ++c)
				alphas_(state, c) = theta[c];
		}
	}

	//
	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		if (alphas_(state, c) < eps)  // already trimmed.
		{
			Ws_(state, c) = 0.0;
			mus_(state, c) = 0.0;
			sigmas_(state, c) = 0.0;
		}
		else
		{
			sumZeta = 0.0;
			for (n = 0; n < N; ++n)
				sumZeta += zeta(n, c);
			assert(std::fabs(sumZeta) > eps);

			// reestimate observation(emission) distribution in each state.

			// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
			double denominatorW = 0.0;  // zeta(0, c) * observations(-1, 0) * observations(-1, 0).
			for (n = 1; n < N; ++n)
				denominatorW += zeta(n, c) * observations(n-1, 0) * observations(n-1, 0);
			assert(std::fabs(denominatorW) >= eps);

			//
			double &W = Ws_(state, c);
			double &mu = mus_(state, c);

			const double tol = 1.0e-5;
			const size_t maxIteration = 1000;
			size_t iteration = 0;
			double oldMu = mu, oldW = W;
			while (iteration < maxIteration)
			{
				// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
				W = 0.0;  // zeta(0, c) * (observations(0, 0) - mu) * observations(-1, 0) = 0.
				for (n = 1; n < N; ++n)
					W += zeta(n, c) * (observations(n, 0) - mu) * observations(n-1, 0);
				W = 0.001 + 0.999 * W / denominatorW;
	
				// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
				mu = zeta(0, c) * observations(0, 0);  // zeta(0, c) * (observations(0, 0) - W * observations(-1, 0)).
				for (n = 1; n < N; ++n)
					mu += zeta(n, c) * (observations(n, 0) - W * observations(n-1, 0));
				mu = 0.001 + 0.999 * mu / sumZeta;

				if (std::fabs(W - oldW) <= tol && std::fabs(mu - oldMu) <= tol)
					break;

				oldW = W;
				oldMu = mu;

				++iteration;
			}

			//
			double &sigma = sigmas_(state, c);
			// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
			sigma = zeta(0, c) * std::pow(observations(0, 0) - mu, 2.0);  // zeta(0, c) * (observations(0, 0) - W * observations(-1, 0) - mu)^2.
			for (n = 1; n < N; ++n)
				sigma += zeta(n, c) * std::pow(observations(n, 0) - W * observations(n-1, 0) - mu, 2.0);
			sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
			assert(sigma > 0.0);
		}
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

void ArHmmWithUnivariateNormalMixtureObservations::doEstimateObservationDensityParametersByMAPUsingEntropicPrior(const std::vector<size_t> &Ns, const unsigned int state, const std::vector<dmatrix_type> &observationSequences, const std::vector<dmatrix_type> &gammas, const double z, const bool doesTrimParameter, const double terminationTolerance, const size_t maxIteration, const size_t R, const double /*denominatorA*/)
{
	const double eps = 1e-50;
	size_t c, n, r;

	// E-step: evaluate zeta.
	// TODO [check] >> frequent memory reallocation may make trouble.
	std::vector<dmatrix_type> zetas;
	zetas.reserve(R);
	for (r = 0; r < R; ++r)
		zetas.push_back(dmatrix_type(Ns[r], C_, 0.0));

	{
		double denominator;
		double val;
		for (r = 0; r < R; ++r)
		{
			const dmatrix_type &observationr = observationSequences[r];
			const dmatrix_type &gammar = gammas[r];
			dmatrix_type &zetar = zetas[r];

			for (n = 0; n < Ns[r]; ++n)
			{
				//const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationr, n);

				denominator = 0.0;
				for (c = 0; c < C_; ++c)
				{
					// TODO [check] >> we need to check if a component is trimmed or not.
					//	Here, we use the value of alpha in order to check if a component is trimmed or not.
					//val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, obs));
					val = std::fabs(alphas_(state, c)) < eps ? 0.0 : (alphas_(state, c) * doEvaluateEmissionMixtureComponentProbability(state, c, n, observationr));

					zetar(n, c) = val;
					denominator += val;  // this value can be nearly zero if the observation is not generated by the corresponding mixture model.
				}

				if (denominator < eps)
				{
					// FIXME [check] >>
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.0;
				}
				else
				{
#if 0
					val = 0.999 * gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) = 0.001 + val * zetar(n, c);
#else
					val = gammar(n, state) / denominator;
					for (c = 0; c < C_; ++c)
						zetar(n, c) *= val;
#endif
				}
			}
		}
	}

	// M-step.
	// reestimate observation(emission) distribution in each state.

	{
		// compute expected sufficient statistics (ESS).
		std::vector<double> omega(C_, 0.0), theta(C_, 0.0);
		for (c = 0; c < C_; ++c)
		{
			omega[c] = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &zetar = zetas[r];
				for (n = 0; n < Ns[r]; ++n)
					omega[c] += zetar(n, c);
			}
		}

		// reestimate mixture coefficients(weights).
		double entropicMAPLogLikelihood = 0.0;
		const bool retval = computeMAPEstimateOfMultinomialUsingEntropicPrior(omega, z, theta, entropicMAPLogLikelihood, terminationTolerance, maxIteration, false);
		assert(retval);

		// trim mixture coefficients(weights).
		if (doesTrimParameter && std::fabs(z - 1.0) <= eps)
		{
			std::vector<dmatrix_type> probs(R);
			for (r = 0; r < R; ++r)
			{
				const size_t &Nr = Ns[r];
				const dmatrix_type &observationr = observationSequences[r];

				dmatrix_type &probr = probs[r];
				probr.resize(Nr, C_);
				for (n = 0; n < Nr; ++n)
				{
					//const boost::numeric::ublas::matrix_row<const dmatrix_type> obs(observationr, n);
					for (c = 0; c < C_; ++c)
					{
						// TODO [check] >> we need to check if a component is trimmed or not.
						//	Here, we use the value of alpha in order to check if a component is trimmed or not.
						//probr(n, c) = std::fabs(alphas_(state, c)) < eps ? 0.0 : doEvaluateEmissionMixtureComponentProbability(state, c, obs);
						probr(n, c) = std::fabs(alphas_(state, c)) < eps ? 0.0 : doEvaluateEmissionMixtureComponentProbability(state, c, n, observationr);
					}
				}
			}

			size_t i;
			double grad;
			bool isNormalized = false;
			double numerator, denominator;
			for (c = 0; c < C_; ++c)
			{
				if (alphas_(state, c) >= eps)  // not yet trimmed.
				{
					grad = 0.0;
					for (r = 0; r < R; ++r)
					{
						const size_t &Nr = Ns[r];
						const dmatrix_type &probr = probs[r];
						for (n = 0; n < Nr; ++n)
						{
							numerator = probr(n, c);
							if (std::fabs(numerator) >= eps)
							{
								denominator = 0.0;
								for (i = 0; i < C_; ++i)
									denominator += probr(n, i) * theta[i];

								assert(std::fabs(denominator) >= eps);
								grad += numerator / denominator;
							}
							//else grad += 0.0;
						}
					}

					if (theta[c] <= std::exp(-grad / z))
					{
						theta[c] = 0.0;
						isNormalized = true;
					}
				}
			}

			if (isNormalized)
			{
				double sumTheta = std::accumulate(theta.begin(), theta.end(), 0.0);
				assert(std::fabs(sumTheta) >= eps);
				for (c = 0; c < C_; ++c)
					alphas_(state, c) = theta[c] / sumTheta;
			}
			else
			{
				for (c = 0; c < C_; ++c)
					alphas_(state, c) = theta[c];
			}
		}
		else
		{
			for (c = 0; c < C_; ++c)
				alphas_(state, c) = theta[c];
		}
	}

	//
	double sumZeta;
	for (c = 0; c < C_; ++c)
	{
		if (alphas_(state, c) < eps)  // already trimmed.
		{
			Ws_(state, c) = 0.0;
			mus_(state, c) = 0.0;
			sigmas_(state, c) = 0.0;
		}
		else
		{
			sumZeta = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &zetar = zetas[r];

				for (n = 0; n < Ns[r]; ++n)
					sumZeta += zetar(n, c);
			}
			assert(std::fabs(sumZeta) > eps);

			// reestimate observation(emission) distribution in each state.

			double denominatorW = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &observationr = observationSequences[r];
				const dmatrix_type &zetar = zetas[r];

				// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
				//denominatorW += 0.0;  // zetar(0, c) * observationr(-1, 0) * observationr(-1, 0) = 0.
				for (n = 1; n < Ns[r]; ++n)
					denominatorW += zetar(n, c) * observationr(n-1, 0) * observationr(n-1, 0);
			}
			assert(std::fabs(denominatorW) >= eps);

			//
			double &W = Ws_(state, c);
			double &mu = mus_(state, c);

			const double tol = 1.0e-5;
			const size_t maxIteration = 1000;
			size_t iteration = 0;
			double oldMu = mu, oldW = W;
			while (iteration < maxIteration)
			{
				W = 0.0;
				for (r = 0; r < R; ++r)
				{
					const dmatrix_type &observationr = observationSequences[r];
					const dmatrix_type &zetar = zetas[r];

					// TODO [check] >> assume x_-1 = observationr(-1, 0) = 0.
					//W += 0.0;  // zetar(0, c) * (observationr(0, 0) - mu) * observationr(-1, 0) = 0.
					for (n = 1; n < Ns[r]; ++n)
						W += zetar(n, c) * (observationr(n, 0) - mu) * observationr(n-1, 0);
				}
				W = 0.001 + 0.999 * W / denominatorW;

				mu = 0.0;
				for (r = 0; r < R; ++r)
				{
					const dmatrix_type &observationr = observationSequences[r];
					const dmatrix_type &zetar = zetas[r];
	
					// TODO [check] >> assume x_-1 = observationr(-1, 0) = 0.
					mu += zetar(0, c) * observationr(0, 0);  // zetar(0, c) * (observationr(0, 0) - W * observationr(-1, 0)).
					for (n = 1; n < Ns[r]; ++n)
						mu += zetar(n, c) * (observationr(n, 0) - W * observationr(n-1, 0));
				}
				mu = 0.001 + 0.999 * mu / sumZeta;

				if (std::fabs(W - oldW) <= tol && std::fabs(mu - oldMu) <= tol)
					break;

				oldW = W;
				oldMu = mu;

				++iteration;
			}

			//
			double &sigma = sigmas_(state, c);
			sigma = 0.0;
			for (r = 0; r < R; ++r)
			{
				const dmatrix_type &observationr = observationSequences[r];
				const dmatrix_type &zetar = zetas[r];

				// TODO [check] >> assume x_-1 = observationr(-1, 0) = 0.
				sigma += zetar(0, c) * std::pow(observationr(0, 0) - mu, 2.0);  // zetar(0, c) * (observationr(0, 0) - W * observationr(-1, 0) - mu)^2.
				for (n = 1; n < Ns[r]; ++n)
					sigma += zetar(n, c) * std::pow(observationr(n, 0) - W * observationr(n-1, 0) - mu, 2.0);
			}
			sigma = 0.001 + 0.999 * std::sqrt(sigma / sumZeta);
			assert(sigma > 0.0);
		}
	}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

double ArHmmWithUnivariateNormalMixtureObservations::doEvaluateEmissionProbability(const unsigned int state, const dvector_type &observation) const
{
	assert(false);

	return base_type::doEvaluateEmissionProbability(state, observation);
}

double ArHmmWithUnivariateNormalMixtureObservations::doEvaluateEmissionProbability(const unsigned int state, const size_t n, const dmatrix_type &observations) const
{
	return base_type::doEvaluateEmissionProbability(state, n, observations);
}

double ArHmmWithUnivariateNormalMixtureObservations::doEvaluateEmissionMixtureComponentProbability(const unsigned int state, const unsigned int component, const dvector_type &observation) const
{
	assert(false);

	//boost::math::normal pdf;  // (default mean = zero, and standard deviation = unity).
	boost::math::normal pdf(mus_(state, component), sigmas_(state, component));

	return boost::math::pdf(pdf, observation[0]);
}

double ArHmmWithUnivariateNormalMixtureObservations::doEvaluateEmissionMixtureComponentProbability(const unsigned int state, const unsigned int component, const size_t n, const dmatrix_type &observations) const
{
	//boost::math::normal pdf;  // (default mean = zero, and standard deviation = unity).
	// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
	boost::math::normal pdf(0 == n ? mus_(state, component) : (Ws_(state, component) * observations(n-1, 0) + mus_(state, component)), sigmas_(state, component));

	return boost::math::pdf(pdf, observations(n, 0));
}

void ArHmmWithUnivariateNormalMixtureObservations::doGenerateObservationsSymbol(const unsigned int state, const size_t n, dmatrix_type &observations) const
{
	const double prob = (double)std::rand() / RAND_MAX;

	double accum = 0.0;
	unsigned int component = (unsigned int)C_;
	for (size_t c = 0; c < C_; ++c)
	{
		accum += alphas_(state, c);
		if (prob < accum)
		{
			component = (unsigned int)c;
			break;
		}
	}

	// TODO [check] >>
	if ((unsigned int)C_ == component)
		component = (unsigned int)(C_ - 1);

	//
	typedef boost::normal_distribution<> distribution_type;
	typedef boost::variate_generator<base_generator_type &, distribution_type> generator_type;

	// TODO [check] >> assume x_-1 = observations(-1, 0) = 0.
	generator_type normal_gen(baseGenerator_, distribution_type(0 == n ? mus_(state, component) : (Ws_(state, component) * observations(n-1, 0) + mus_(state, component)), sigmas_(state, component)));
	observations(n, 0) = normal_gen();
}

void ArHmmWithUnivariateNormalMixtureObservations::doInitializeRandomSampleGeneration(const unsigned int seed /*= (unsigned int)-1*/) const
{
	if ((unsigned int)-1 != seed)
	{
		std::srand(seed);
		baseGenerator_.seed(seed);
	}
}

bool ArHmmWithUnivariateNormalMixtureObservations::doReadObservationDensity(std::istream &stream)
{
	if (1 != D_) return false;

	std::string dummy;
	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "ar") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "ar") != 0)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "univariate") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "univariate") != 0)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "normal") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "normal") != 0)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "mixture:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "mixture:") != 0)
#endif
		return false;

	// TODO [check] >>
	size_t C;
	stream >> dummy >> C;  // the number of mixture components.
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "C=") != 0 || C_ != C)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "C=") != 0 || C_ != C)
#endif
		return false;

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "alpha:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "alpha:") != 0)
#endif
		return false;

	size_t k, c;

	// K x C.
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> alphas_(k, c);

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "W:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "W:") != 0)
#endif
		return false;

	// K x C.
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> Ws_(k, c);

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "mu:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "mu:") != 0)
#endif
		return false;

	// K x C.
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> mus_(k, c);

	stream >> dummy;
#if defined(__GNUC__)
	if (strcasecmp(dummy.c_str(), "sigma:") != 0)
#elif defined(_MSC_VER)
	if (_stricmp(dummy.c_str(), "sigma:") != 0)
#endif
		return false;

	// K x C.
	for (k = 0; k < K_; ++k)
		for (c = 0; c < C_; ++c)
			stream >> sigmas_(k, c);

	return true;
}

bool ArHmmWithUnivariateNormalMixtureObservations::doWriteObservationDensity(std::ostream &stream) const
{
	stream << "ar univariate normal mixture:" << std::endl;

	stream << "C= " << C_ << std::endl;  // the number of mixture components.

	size_t k, c;

	// K x C.
	stream << "alpha:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << alphas_(k, c) << ' ';
		stream << std::endl;
	}

	// K x C.
	stream << "W:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << Ws_(k, c) << ' ';
		stream << std::endl;
	}

	// K x C.
	stream << "mu:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << mus_(k, c) << ' ';
		stream << std::endl;
	}

	// K x C.
	stream << "sigma:" << std::endl;
	for (k = 0; k < K_; ++k)
	{
		for (c = 0; c < C_; ++c)
			stream << sigmas_(k, c) << ' ';
		stream << std::endl;
	}

	return true;
}

void ArHmmWithUnivariateNormalMixtureObservations::doInitializeObservationDensity(const std::vector<double> &lowerBoundsOfObservationDensity, const std::vector<double> &upperBoundsOfObservationDensity)
{
	// PRECONDITIONS [] >>
	//	-. std::srand() has to be called before this function is called.

	// initialize mixture coefficients(weights).
	{
		double sum = 0.0;
		size_t c;
		for (size_t k = 0; k < K_; ++k)
		{
			for (c = 0; c < C_; ++c)
			{
				alphas_(k, c) = (double)std::rand() / RAND_MAX;
				sum += alphas_(k, c);
			}
			for (c = 0; c < C_; ++c)
				alphas_(k, c) /= sum;
		}
	}

	// initialize the parameters of observation density.
	const std::size_t numLowerBound = lowerBoundsOfObservationDensity.size();
	const std::size_t numUpperBound = upperBoundsOfObservationDensity.size();

	const std::size_t numParameters = K_ * C_ * D_ * 3;  // the total number of parameters of observation density.

	assert(numLowerBound == numUpperBound);
	assert(1 == numLowerBound || numParameters == numLowerBound);

	if (1 == numLowerBound)
	{
		const double lb = lowerBoundsOfObservationDensity[0], ub = upperBoundsOfObservationDensity[0];
		size_t c;
		for (size_t k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c)
			{
				Ws_(k, c) = ((double)std::rand() / RAND_MAX) * (ub - lb) + lb;
				mus_(k, c) = ((double)std::rand() / RAND_MAX) * (ub - lb) + lb;
				// TODO [check] >> all standard deviations have to be positive.
				sigmas_(k, c) = ((double)std::rand() / RAND_MAX) * (ub - lb) + lb;
			}
 	}
	else if (numParameters == numLowerBound)
	{
		size_t k, c, idx = 0;
		for (k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c, ++idx)
				Ws_(k, c) = ((double)std::rand() / RAND_MAX) * (upperBoundsOfObservationDensity[idx] - lowerBoundsOfObservationDensity[idx]) + lowerBoundsOfObservationDensity[idx];
		for (k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c, ++idx)
				mus_(k, c) = ((double)std::rand() / RAND_MAX) * (upperBoundsOfObservationDensity[idx] - lowerBoundsOfObservationDensity[idx]) + lowerBoundsOfObservationDensity[idx];
		for (k = 0; k < K_; ++k)
			for (c = 0; c < C_; ++c, ++idx)
				// TODO [check] >> all standard deviations have to be positive.
				sigmas_(k, c) = ((double)std::rand() / RAND_MAX) * (upperBoundsOfObservationDensity[idx] - lowerBoundsOfObservationDensity[idx]) + lowerBoundsOfObservationDensity[idx];
	}

	for (size_t k = 0; k < K_; ++k)
		for (size_t c = 0; c < C_; ++c)
		{
			// all standard deviations have to be positive.
			if (sigmas_(k, c) < 0.0)
				sigmas_(k, c) = -sigmas_(k, c);
		}

	// POSTCONDITIONS [] >>
	//	-. all standard deviations have to be positive.
}

}  // namespace swl
